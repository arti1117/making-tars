{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7873f8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.300512454861974\n",
      "=== epoch:1, train acc:0.212, test acc:0.192 ===\n",
      "train loss:2.297410177810794\n",
      "train loss:2.29540212084345\n",
      "train loss:2.2881264930952083\n",
      "train loss:2.279694664223647\n",
      "train loss:2.2697035001094776\n",
      "train loss:2.2622907006586246\n",
      "train loss:2.2401277778340196\n",
      "train loss:2.2200135700680836\n",
      "train loss:2.194149256481648\n",
      "train loss:2.1529252810577275\n",
      "train loss:2.1252868793593604\n",
      "train loss:2.0825172182075464\n",
      "train loss:2.0540065027846377\n",
      "train loss:1.9903595518041033\n",
      "train loss:1.8562117087869716\n",
      "train loss:1.8612746705923535\n",
      "train loss:1.8925554085917862\n",
      "train loss:1.7159795254458243\n",
      "train loss:1.64189318599643\n",
      "train loss:1.634123149386804\n",
      "train loss:1.4699954768764192\n",
      "train loss:1.4344875216123674\n",
      "train loss:1.2905173306800257\n",
      "train loss:1.2092209066555424\n",
      "train loss:1.1625940819605958\n",
      "train loss:1.0575803776606727\n",
      "train loss:1.099994947269267\n",
      "train loss:0.9277525931653224\n",
      "train loss:0.9048793825252401\n",
      "train loss:0.824932097760183\n",
      "train loss:0.930298872505237\n",
      "train loss:0.895133076823775\n",
      "train loss:0.7627564985900104\n",
      "train loss:0.7689785434064058\n",
      "train loss:0.9605342033640619\n",
      "train loss:0.858752701489709\n",
      "train loss:0.772113793620226\n",
      "train loss:0.6764889331162882\n",
      "train loss:0.6683183316891511\n",
      "train loss:0.7687359234172314\n",
      "train loss:0.6696345767719404\n",
      "train loss:0.5296162848428623\n",
      "train loss:0.636180962494014\n",
      "train loss:0.803845632019091\n",
      "train loss:0.5090737855828034\n",
      "train loss:0.49332940965124644\n",
      "train loss:0.4408134881870589\n",
      "train loss:0.6994470850222654\n",
      "train loss:0.6370923645251634\n",
      "train loss:0.6267901998159151\n",
      "train loss:0.753871074321263\n",
      "train loss:0.4182976153379297\n",
      "train loss:0.4879239284390856\n",
      "train loss:0.5923602956320471\n",
      "train loss:0.3546397554833382\n",
      "train loss:0.3227507392001991\n",
      "train loss:0.4294739466162498\n",
      "train loss:0.6035451438319432\n",
      "train loss:0.46181505021984093\n",
      "train loss:0.4328511954407845\n",
      "train loss:0.530578147759854\n",
      "train loss:0.35336335431798505\n",
      "train loss:0.37439252890553376\n",
      "train loss:0.8460384637748029\n",
      "train loss:0.4488145831545016\n",
      "train loss:0.46966047458950627\n",
      "train loss:0.44969756082319456\n",
      "train loss:0.3638501342618688\n",
      "train loss:0.5246534440109223\n",
      "train loss:0.25966497381433373\n",
      "train loss:0.4529722627610669\n",
      "train loss:0.3755439972187621\n",
      "train loss:0.5016385128103947\n",
      "train loss:0.47124206131407503\n",
      "train loss:0.5325199224770801\n",
      "train loss:0.4022359791480503\n",
      "train loss:0.4180049306659263\n",
      "train loss:0.39241033625231053\n",
      "train loss:0.4116967611097541\n",
      "train loss:0.2853427083069987\n",
      "train loss:0.5124450672992782\n",
      "train loss:0.33220445856266656\n",
      "train loss:0.47360715136733367\n",
      "train loss:0.3459724882239805\n",
      "train loss:0.46590134570564773\n",
      "train loss:0.3824071113517559\n",
      "train loss:0.505758590836501\n",
      "train loss:0.32680669985840594\n",
      "train loss:0.5936266439757051\n",
      "train loss:0.33011126214512226\n",
      "train loss:0.4379931444697806\n",
      "train loss:0.40115894128720747\n",
      "train loss:0.36398501574529296\n",
      "train loss:0.4301341714607808\n",
      "train loss:0.21249583206507264\n",
      "train loss:0.34968966082584585\n",
      "train loss:0.3433490498856054\n",
      "train loss:0.2080944648429353\n",
      "train loss:0.35386479028324125\n",
      "train loss:0.2739821677696929\n",
      "train loss:0.43123192949613864\n",
      "train loss:0.3427696334378259\n",
      "train loss:0.4044486627460578\n",
      "train loss:0.35329825421541544\n",
      "train loss:0.3905708646102877\n",
      "train loss:0.2558402685640053\n",
      "train loss:0.2770865325253586\n",
      "train loss:0.3622727781343492\n",
      "train loss:0.4314311065497277\n",
      "train loss:0.49431547194243103\n",
      "train loss:0.3305153413651163\n",
      "train loss:0.3830340141336927\n",
      "train loss:0.4522380028687067\n",
      "train loss:0.35184033349904875\n",
      "train loss:0.18713640385995992\n",
      "train loss:0.5448688065326166\n",
      "train loss:0.3790005687591273\n",
      "train loss:0.4649477063175609\n",
      "train loss:0.3321923738485473\n",
      "train loss:0.44731292180698495\n",
      "train loss:0.3137109202727935\n",
      "train loss:0.2741086412592726\n",
      "train loss:0.2716304875218933\n",
      "train loss:0.24659340442894695\n",
      "train loss:0.35359532609537486\n",
      "train loss:0.38361430349118203\n",
      "train loss:0.29631236459362603\n",
      "train loss:0.3571038305567381\n",
      "train loss:0.264740420749123\n",
      "train loss:0.2600586333404647\n",
      "train loss:0.3296151813003808\n",
      "train loss:0.24205795505978817\n",
      "train loss:0.298298132352896\n",
      "train loss:0.208389448438379\n",
      "train loss:0.3155208283828418\n",
      "train loss:0.3387581333380171\n",
      "train loss:0.31545394844449715\n",
      "train loss:0.40776013505774666\n",
      "train loss:0.390871154018845\n",
      "train loss:0.26990436830693676\n",
      "train loss:0.5391694557224468\n",
      "train loss:0.16753779385992246\n",
      "train loss:0.2020245996788214\n",
      "train loss:0.20044457334554905\n",
      "train loss:0.2854883984173005\n",
      "train loss:0.4565605801893583\n",
      "train loss:0.30277633812740645\n",
      "train loss:0.34103015172808887\n",
      "train loss:0.24260485260151882\n",
      "train loss:0.23721208687953407\n",
      "train loss:0.2698359406512426\n",
      "train loss:0.19433447236747564\n",
      "train loss:0.26443460273787034\n",
      "train loss:0.28170984108753333\n",
      "train loss:0.25658191979589406\n",
      "train loss:0.19373620853480358\n",
      "train loss:0.6250364823855545\n",
      "train loss:0.33347327993702935\n",
      "train loss:0.36820182000272506\n",
      "train loss:0.2498499048985977\n",
      "train loss:0.34650249724186266\n",
      "train loss:0.33059919311192004\n",
      "train loss:0.20935297422585067\n",
      "train loss:0.2577499787141433\n",
      "train loss:0.23625082250978957\n",
      "train loss:0.25960163468178976\n",
      "train loss:0.29574481968747723\n",
      "train loss:0.22312650820001917\n",
      "train loss:0.23621264958893634\n",
      "train loss:0.23441621043126784\n",
      "train loss:0.29692146534801406\n",
      "train loss:0.2789636566190772\n",
      "train loss:0.15702143263951887\n",
      "train loss:0.39426122385742196\n",
      "train loss:0.1879927732550576\n",
      "train loss:0.1613743625798815\n",
      "train loss:0.26793916096110465\n",
      "train loss:0.24252449255439765\n",
      "train loss:0.35053283062123514\n",
      "train loss:0.2209665706259793\n",
      "train loss:0.3189727530975336\n",
      "train loss:0.2302746397475794\n",
      "train loss:0.25829931592937205\n",
      "train loss:0.4310813828730752\n",
      "train loss:0.20621357947791735\n",
      "train loss:0.21348635101152547\n",
      "train loss:0.14820415208853302\n",
      "train loss:0.25117846185515064\n",
      "train loss:0.28130447818391785\n",
      "train loss:0.3398086927639211\n",
      "train loss:0.251619303275234\n",
      "train loss:0.18402690886368855\n",
      "train loss:0.1627264059416692\n",
      "train loss:0.25371908834718176\n",
      "train loss:0.23284315671525527\n",
      "train loss:0.4063242061152292\n",
      "train loss:0.389478504120677\n",
      "train loss:0.17223903745736277\n",
      "train loss:0.4191810530811459\n",
      "train loss:0.20609558246325624\n",
      "train loss:0.1969065787469073\n",
      "train loss:0.26585416816659363\n",
      "train loss:0.2143456055639434\n",
      "train loss:0.11937442321809065\n",
      "train loss:0.16728690446556857\n",
      "train loss:0.3038103341782871\n",
      "train loss:0.2453070082287126\n",
      "train loss:0.26853951708626206\n",
      "train loss:0.27572979033281564\n",
      "train loss:0.327530022013445\n",
      "train loss:0.25098650929465527\n",
      "train loss:0.25250887219066037\n",
      "train loss:0.23400121281398736\n",
      "train loss:0.2447211735007121\n",
      "train loss:0.29777114912856606\n",
      "train loss:0.27814756569054944\n",
      "train loss:0.14278057653853643\n",
      "train loss:0.33807423030522527\n",
      "train loss:0.2506225054710596\n",
      "train loss:0.20846866963884778\n",
      "train loss:0.14089773595727084\n",
      "train loss:0.2389957774101479\n",
      "train loss:0.18759572085476425\n",
      "train loss:0.1923998320546637\n",
      "train loss:0.2799089343275161\n",
      "train loss:0.3697669098401894\n",
      "train loss:0.2586967997341205\n",
      "train loss:0.21680377044423402\n",
      "train loss:0.2984077483253077\n",
      "train loss:0.4102147200150676\n",
      "train loss:0.10439042694840288\n",
      "train loss:0.4075888685236203\n",
      "train loss:0.2580331051186154\n",
      "train loss:0.3647050109003429\n",
      "train loss:0.2101265076750836\n",
      "train loss:0.4366897796192862\n",
      "train loss:0.24078269963878315\n",
      "train loss:0.19324771578183783\n",
      "train loss:0.2732847905698558\n",
      "train loss:0.15121466552700985\n",
      "train loss:0.3225480061455238\n",
      "train loss:0.20877564371801063\n",
      "train loss:0.1534321276313114\n",
      "train loss:0.1624557277016401\n",
      "train loss:0.13866690395389705\n",
      "train loss:0.19524639875485583\n",
      "train loss:0.11670004790956436\n",
      "train loss:0.11427499295379008\n",
      "train loss:0.21903577411996156\n",
      "train loss:0.4009524485331299\n",
      "train loss:0.20467372352043886\n",
      "train loss:0.21782368117902012\n",
      "train loss:0.2891174465569445\n",
      "train loss:0.3017349168606612\n",
      "train loss:0.20052263447665122\n",
      "train loss:0.08762256908286557\n",
      "train loss:0.14552204986333722\n",
      "train loss:0.21781104201203533\n",
      "train loss:0.2166036263190549\n",
      "train loss:0.23742825260439462\n",
      "train loss:0.21023429900091237\n",
      "train loss:0.16688018648740724\n",
      "train loss:0.26165927913458836\n",
      "train loss:0.1485431530817326\n",
      "train loss:0.289525053955345\n",
      "train loss:0.23685625974175292\n",
      "train loss:0.31397713061802823\n",
      "train loss:0.11773921244764729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.13218986059170196\n",
      "train loss:0.2624964743397763\n",
      "train loss:0.21325823601176508\n",
      "train loss:0.3658251064091101\n",
      "train loss:0.1389904851426997\n",
      "train loss:0.13476877848679308\n",
      "train loss:0.2518869198394127\n",
      "train loss:0.19127859518789134\n",
      "train loss:0.09168605260034847\n",
      "train loss:0.13355715299083246\n",
      "train loss:0.19182060797620157\n",
      "train loss:0.2337998993121279\n",
      "train loss:0.18308454446939762\n",
      "train loss:0.22542036614884647\n",
      "train loss:0.08149196774003332\n",
      "train loss:0.22275542632022205\n",
      "train loss:0.17099885102418744\n",
      "train loss:0.11273801338153712\n",
      "train loss:0.1607214785882504\n",
      "train loss:0.19747388548415729\n",
      "train loss:0.18854041515215286\n",
      "train loss:0.16143425354794672\n",
      "train loss:0.14433275830099407\n",
      "train loss:0.19300931400585808\n",
      "train loss:0.189719968969489\n",
      "train loss:0.28324043620153494\n",
      "train loss:0.07120166468752259\n",
      "train loss:0.2134190363973028\n",
      "train loss:0.10751890368664636\n",
      "train loss:0.17915962648112932\n",
      "train loss:0.16958128996189628\n",
      "train loss:0.20445675195279475\n",
      "train loss:0.2890375786819393\n",
      "train loss:0.18130441822856194\n",
      "train loss:0.1087298521285391\n",
      "train loss:0.19437662548143086\n",
      "train loss:0.22660759780501674\n",
      "train loss:0.14978567176603513\n",
      "train loss:0.1397684265381173\n",
      "train loss:0.19138148823836226\n",
      "train loss:0.06758841958492808\n",
      "train loss:0.2129158671570332\n",
      "train loss:0.16444225552245967\n",
      "train loss:0.17126950436295496\n",
      "train loss:0.26303754408977364\n",
      "train loss:0.34394338869667407\n",
      "train loss:0.22474564858745472\n",
      "train loss:0.27252748839515645\n",
      "train loss:0.11480003609485795\n",
      "train loss:0.16118536660641003\n",
      "train loss:0.2249773530713428\n",
      "train loss:0.23152204915836808\n",
      "train loss:0.14473797764402754\n",
      "train loss:0.2282860485144448\n",
      "train loss:0.13331809534193337\n",
      "train loss:0.1321933732862273\n",
      "train loss:0.1223004888704555\n",
      "train loss:0.16466680717421833\n",
      "train loss:0.18315866173284254\n",
      "train loss:0.15575797144327186\n",
      "train loss:0.2632211741397364\n",
      "train loss:0.13683377318359577\n",
      "train loss:0.34757360776349233\n",
      "train loss:0.09317611011949918\n",
      "train loss:0.14854321910415122\n",
      "train loss:0.19217845472058898\n",
      "train loss:0.17627471906286538\n",
      "train loss:0.14113925054382256\n",
      "train loss:0.13485525342996785\n",
      "train loss:0.2708044066468344\n",
      "train loss:0.2440073610972443\n",
      "train loss:0.15408288022696093\n",
      "train loss:0.16813315859572575\n",
      "train loss:0.15740462275137884\n",
      "train loss:0.3170245785901669\n",
      "train loss:0.1269564556044901\n",
      "train loss:0.16482684404135764\n",
      "train loss:0.24928340422614564\n",
      "train loss:0.1630347413226417\n",
      "train loss:0.15841611736848132\n",
      "train loss:0.24512366079565504\n",
      "train loss:0.17856874502760894\n",
      "train loss:0.2470786888529646\n",
      "train loss:0.12883363793588287\n",
      "train loss:0.231237876384364\n",
      "train loss:0.14216812952063862\n",
      "train loss:0.09565111988226409\n",
      "train loss:0.1620099767617055\n",
      "train loss:0.2572046560182606\n",
      "train loss:0.10275528870549464\n",
      "train loss:0.06577070220947266\n",
      "train loss:0.14358838425854553\n",
      "train loss:0.16735512723220528\n",
      "train loss:0.11846726230183727\n",
      "train loss:0.24710747941868388\n",
      "train loss:0.10472387215878692\n",
      "train loss:0.12552687377024985\n",
      "train loss:0.1218670460865612\n",
      "train loss:0.13534663212512577\n",
      "train loss:0.2979094144619295\n",
      "train loss:0.10492686434234189\n",
      "train loss:0.19835204726946043\n",
      "train loss:0.24814791393648794\n",
      "train loss:0.1369322246289806\n",
      "train loss:0.2481028818037012\n",
      "train loss:0.14330257799725898\n",
      "train loss:0.16530772661578322\n",
      "train loss:0.16371735622682157\n",
      "train loss:0.10637189209490293\n",
      "train loss:0.1086761655203824\n",
      "train loss:0.1878251715668567\n",
      "train loss:0.08185267516330257\n",
      "train loss:0.32640490175825065\n",
      "train loss:0.1327622115388104\n",
      "train loss:0.11302405469152133\n",
      "train loss:0.23089294212276068\n",
      "train loss:0.1078183030660828\n",
      "train loss:0.16807396271049896\n",
      "train loss:0.1290385672324283\n",
      "train loss:0.15541988671933366\n",
      "train loss:0.0917235199444874\n",
      "train loss:0.16109846071468759\n",
      "train loss:0.18746251360258076\n",
      "train loss:0.09506121678221272\n",
      "train loss:0.1865492832472951\n",
      "train loss:0.22562987072945448\n",
      "train loss:0.13465060528080586\n",
      "train loss:0.09512320308395075\n",
      "train loss:0.12042754892776814\n",
      "train loss:0.10788430127198378\n",
      "train loss:0.18219118361678574\n",
      "train loss:0.24824539352518735\n",
      "train loss:0.13401416100154953\n",
      "train loss:0.20321043677532397\n",
      "train loss:0.09904295234814615\n",
      "train loss:0.13467537708178412\n",
      "train loss:0.14136145986230444\n",
      "train loss:0.20852368903245774\n",
      "train loss:0.15642772663919824\n",
      "train loss:0.04858658723984353\n",
      "train loss:0.2476476307331062\n",
      "train loss:0.1804032489578518\n",
      "train loss:0.13877879661173487\n",
      "train loss:0.13371497566475482\n",
      "train loss:0.06657641375385262\n",
      "train loss:0.09172073421450574\n",
      "train loss:0.21144100186006248\n",
      "train loss:0.1333396549719807\n",
      "train loss:0.16010899202840267\n",
      "train loss:0.13088653053676103\n",
      "train loss:0.20744025560182705\n",
      "train loss:0.09018410714921772\n",
      "train loss:0.0837587602531511\n",
      "train loss:0.17112963882338875\n",
      "train loss:0.15487249565731367\n",
      "train loss:0.21206760032530084\n",
      "train loss:0.10284587771397699\n",
      "train loss:0.1536323276973598\n",
      "train loss:0.11399368942794658\n",
      "train loss:0.173339654446985\n",
      "train loss:0.28653387102541666\n",
      "train loss:0.18647782060942386\n",
      "train loss:0.13482119723571684\n",
      "train loss:0.16872374272530663\n",
      "train loss:0.10316078995739163\n",
      "train loss:0.10332138767890893\n",
      "train loss:0.11035503784022897\n",
      "train loss:0.2799478227686097\n",
      "train loss:0.06630382601341359\n",
      "train loss:0.054734459337071543\n",
      "train loss:0.14915742463010295\n",
      "train loss:0.2491175579473847\n",
      "train loss:0.09918386533890576\n",
      "train loss:0.05558505234539941\n",
      "train loss:0.18103613924673478\n",
      "train loss:0.15617660359021424\n",
      "train loss:0.08611621525188402\n",
      "train loss:0.10162887468950316\n",
      "train loss:0.12948513845362358\n",
      "train loss:0.070166910958255\n",
      "train loss:0.08703975968863827\n",
      "train loss:0.11473171055290879\n",
      "train loss:0.15746501960156326\n",
      "train loss:0.153726335822875\n",
      "train loss:0.2191661861708286\n",
      "train loss:0.13145620200276217\n",
      "train loss:0.18538716554653212\n",
      "train loss:0.12593821605125627\n",
      "train loss:0.2504109282486897\n",
      "train loss:0.1284809033313833\n",
      "train loss:0.07471839153101048\n",
      "train loss:0.034272697844582284\n",
      "train loss:0.04502293096916749\n",
      "train loss:0.15541598566498047\n",
      "train loss:0.16514562282134546\n",
      "train loss:0.10464063007076146\n",
      "train loss:0.06105937743397985\n",
      "train loss:0.19127864664399624\n",
      "train loss:0.10285754048035227\n",
      "train loss:0.14106472294430925\n",
      "train loss:0.07395963802091433\n",
      "train loss:0.0864815485483801\n",
      "train loss:0.05864701398265274\n",
      "train loss:0.2055048634180635\n",
      "train loss:0.062167696641394335\n",
      "train loss:0.15346634684032562\n",
      "train loss:0.09582059213684736\n",
      "train loss:0.08969087279321095\n",
      "train loss:0.0964468972435135\n",
      "train loss:0.0842284786653156\n",
      "train loss:0.13485125250346924\n",
      "train loss:0.15182997543413015\n",
      "train loss:0.07505299896430628\n",
      "train loss:0.08505690111180211\n",
      "train loss:0.2651201612735336\n",
      "train loss:0.0828990641334499\n",
      "train loss:0.05206673577645466\n",
      "train loss:0.12143890966602147\n",
      "train loss:0.13030556075173766\n",
      "train loss:0.07424507312960121\n",
      "train loss:0.09187279151861576\n",
      "train loss:0.0808316895253976\n",
      "train loss:0.10794306328750565\n",
      "train loss:0.10584644070641369\n",
      "train loss:0.18279429785359094\n",
      "train loss:0.10441271197187856\n",
      "train loss:0.1317095588995302\n",
      "train loss:0.14705349655094413\n",
      "train loss:0.09010425707026187\n",
      "train loss:0.06546930374908198\n",
      "train loss:0.1126872040779619\n",
      "train loss:0.06434548438638417\n",
      "train loss:0.12047231616718151\n",
      "train loss:0.05332908387236861\n",
      "train loss:0.10203894964367706\n",
      "train loss:0.20129768590378422\n",
      "train loss:0.20694306800726647\n",
      "train loss:0.1425602763762582\n",
      "train loss:0.1633921176464318\n",
      "train loss:0.1844392859487834\n",
      "train loss:0.0632668382381494\n",
      "train loss:0.05472314037708133\n",
      "train loss:0.09566184996679994\n",
      "train loss:0.08037148616508727\n",
      "train loss:0.21053758484505183\n",
      "train loss:0.1705992269741538\n",
      "train loss:0.1263734087513597\n",
      "train loss:0.0823371540748974\n",
      "train loss:0.1480871461214296\n",
      "train loss:0.1407486288026629\n",
      "train loss:0.1300864092412367\n",
      "train loss:0.1116069454717235\n",
      "train loss:0.12586428794285284\n",
      "train loss:0.05708889087443594\n",
      "train loss:0.1592179550701056\n",
      "train loss:0.10507327719665716\n",
      "train loss:0.3659958172989831\n",
      "train loss:0.16934937048034304\n",
      "train loss:0.10541031368864046\n",
      "train loss:0.10594172791416283\n",
      "train loss:0.11435311447722359\n",
      "train loss:0.12043127669961935\n",
      "train loss:0.1536180131783273\n",
      "train loss:0.18252212088431374\n",
      "train loss:0.13507478326032762\n",
      "train loss:0.14382449509560702\n",
      "train loss:0.06618523841284822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.10810022001823899\n",
      "train loss:0.07894840628861535\n",
      "train loss:0.09159377123401823\n",
      "train loss:0.1234845144593634\n",
      "train loss:0.15760055237806436\n",
      "train loss:0.09001957814874478\n",
      "train loss:0.06220803407152279\n",
      "train loss:0.05577429976180487\n",
      "train loss:0.14845336211103993\n",
      "train loss:0.15575671268241637\n",
      "train loss:0.18194408195645648\n",
      "train loss:0.08749739558374678\n",
      "train loss:0.23938130347676398\n",
      "train loss:0.16080874772340015\n",
      "train loss:0.10981169746328388\n",
      "train loss:0.16387453235865934\n",
      "train loss:0.12646518727276462\n",
      "train loss:0.11424970108120464\n",
      "train loss:0.06918733095148812\n",
      "train loss:0.15720316833468723\n",
      "train loss:0.12594389521920601\n",
      "train loss:0.2751316845419176\n",
      "train loss:0.082522498785807\n",
      "train loss:0.0632195376990989\n",
      "train loss:0.09093699075584695\n",
      "train loss:0.11573406135579589\n",
      "train loss:0.08508295325773008\n",
      "train loss:0.04200976243805794\n",
      "train loss:0.1407930363257253\n",
      "train loss:0.07022632432119556\n",
      "train loss:0.16404922952915058\n",
      "train loss:0.06325248014798397\n",
      "train loss:0.052620583402861076\n",
      "train loss:0.14729627490377992\n",
      "train loss:0.14848874125240125\n",
      "train loss:0.062446416365708836\n",
      "train loss:0.054448788750872675\n",
      "train loss:0.1546022063128829\n",
      "train loss:0.21712318559191018\n",
      "train loss:0.1433798299842588\n",
      "train loss:0.03308953388870958\n",
      "train loss:0.06190047868725798\n",
      "train loss:0.059439000757486926\n",
      "train loss:0.07051933986848705\n",
      "train loss:0.1258296998009184\n",
      "train loss:0.03834533237133534\n",
      "train loss:0.10896036697337257\n",
      "train loss:0.08555025627111316\n",
      "train loss:0.23142407335676954\n",
      "train loss:0.13323412031576315\n",
      "train loss:0.09743552030361353\n",
      "train loss:0.15106470537032418\n",
      "train loss:0.08793882270442457\n",
      "train loss:0.17672865971499063\n",
      "train loss:0.1279304822332305\n",
      "train loss:0.10326804165076227\n",
      "train loss:0.07907512863752512\n",
      "train loss:0.1019830441117683\n",
      "train loss:0.10200790045459246\n",
      "train loss:0.0891167304169968\n",
      "train loss:0.0973300685110717\n",
      "train loss:0.11875556602330484\n",
      "train loss:0.08852020167087744\n",
      "train loss:0.137578832951614\n",
      "train loss:0.05073789891099306\n",
      "=== epoch:2, train acc:0.974, test acc:0.971 ===\n",
      "train loss:0.08098452875954058\n",
      "train loss:0.19707761419776035\n",
      "train loss:0.13774932462892503\n",
      "train loss:0.1569355494890054\n",
      "train loss:0.049232141644965345\n",
      "train loss:0.13557469308956763\n",
      "train loss:0.11063728404850666\n",
      "train loss:0.09463444601454662\n",
      "train loss:0.319457716583533\n",
      "train loss:0.19074957482205723\n",
      "train loss:0.03986330205040023\n",
      "train loss:0.13068498168123832\n",
      "train loss:0.06833521142681226\n",
      "train loss:0.07929572508823955\n",
      "train loss:0.07456046633068623\n",
      "train loss:0.12759673006080105\n",
      "train loss:0.14456525585276736\n",
      "train loss:0.09701304280980541\n",
      "train loss:0.055286288782661605\n",
      "train loss:0.1999282294463146\n",
      "train loss:0.06820533221293792\n",
      "train loss:0.07232258584016985\n",
      "train loss:0.05651064301366935\n",
      "train loss:0.12353121317672999\n",
      "train loss:0.15534493563312138\n",
      "train loss:0.07908293329190184\n",
      "train loss:0.0899006355002513\n",
      "train loss:0.17944336573249195\n",
      "train loss:0.10859678561475268\n",
      "train loss:0.10636049198499187\n",
      "train loss:0.0913303769130179\n",
      "train loss:0.07161908903909481\n",
      "train loss:0.09354891771292204\n",
      "train loss:0.09059101569096073\n",
      "train loss:0.1089640140612692\n",
      "train loss:0.08303832018099039\n",
      "train loss:0.044668084806163605\n",
      "train loss:0.12206644046022826\n",
      "train loss:0.2115821405211667\n",
      "train loss:0.15208129472836507\n",
      "train loss:0.11551618112135914\n",
      "train loss:0.1449780618279952\n",
      "train loss:0.060886094057844786\n",
      "train loss:0.14563901393663553\n",
      "train loss:0.05042239897163321\n",
      "train loss:0.09425969333790996\n",
      "train loss:0.06911348890497529\n",
      "train loss:0.04854388368182517\n",
      "train loss:0.062189542633747416\n",
      "train loss:0.06202300618324753\n",
      "train loss:0.18452098501372166\n",
      "train loss:0.10593083630733266\n",
      "train loss:0.10898103024935406\n",
      "train loss:0.11256059847769892\n",
      "train loss:0.07079942185208865\n",
      "train loss:0.058128354105136434\n",
      "train loss:0.032711127774907124\n",
      "train loss:0.0588366500604336\n",
      "train loss:0.09111422263186154\n",
      "train loss:0.09365695711137213\n",
      "train loss:0.11015325214666882\n",
      "train loss:0.09699712601429766\n",
      "train loss:0.03843389823359359\n",
      "train loss:0.08595550626604868\n",
      "train loss:0.20783129275168072\n",
      "train loss:0.20632759658212493\n",
      "train loss:0.0912709971767423\n",
      "train loss:0.09555103523932075\n",
      "train loss:0.12950530242086467\n",
      "train loss:0.06557935165074212\n",
      "train loss:0.07698153073652608\n",
      "train loss:0.1725947330111527\n",
      "train loss:0.1255857168340347\n",
      "train loss:0.19707448760537208\n",
      "train loss:0.1061134432723459\n",
      "train loss:0.14726309902996973\n",
      "train loss:0.07464338471151205\n",
      "train loss:0.1032813374405082\n",
      "train loss:0.12303394003959862\n",
      "train loss:0.15395697674959888\n",
      "train loss:0.0702272031432758\n",
      "train loss:0.09015629087858999\n",
      "train loss:0.14508363148317513\n",
      "train loss:0.05514992139938336\n",
      "train loss:0.07264597118360018\n",
      "train loss:0.1180613064424632\n",
      "train loss:0.059750391763323266\n",
      "train loss:0.05823322616049808\n",
      "train loss:0.10483671505294018\n",
      "train loss:0.09901492796773673\n",
      "train loss:0.06953219894733503\n",
      "train loss:0.12659599327645168\n",
      "train loss:0.10473038491200418\n",
      "train loss:0.06562016281988842\n",
      "train loss:0.13914692856193558\n",
      "train loss:0.11119702368344145\n",
      "train loss:0.04201476646550583\n",
      "train loss:0.029928146438477583\n",
      "train loss:0.14535924046535117\n",
      "train loss:0.078724152378689\n",
      "train loss:0.08009971304646703\n",
      "train loss:0.10111545487439023\n",
      "train loss:0.1053592908148737\n",
      "train loss:0.03201831564631068\n",
      "train loss:0.049542823571883575\n",
      "train loss:0.12054118814685942\n",
      "train loss:0.12339868928339019\n",
      "train loss:0.09656029200956215\n",
      "train loss:0.05988798066376418\n",
      "train loss:0.0913786267802117\n",
      "train loss:0.03643292842475298\n",
      "train loss:0.09952614605585465\n",
      "train loss:0.05921408534007761\n",
      "train loss:0.17646494802400825\n",
      "train loss:0.05031820838247367\n",
      "train loss:0.03437201507375437\n",
      "train loss:0.029865480059578352\n",
      "train loss:0.07744532656640321\n",
      "train loss:0.05694966592762411\n",
      "train loss:0.07933637471586649\n",
      "train loss:0.08523113906706672\n",
      "train loss:0.047622488404193024\n",
      "train loss:0.09970770109848362\n",
      "train loss:0.08928624554047021\n",
      "train loss:0.12103814024970028\n",
      "train loss:0.1494088600990903\n",
      "train loss:0.09615965393895577\n",
      "train loss:0.11714832720812396\n",
      "train loss:0.13060106853154288\n",
      "train loss:0.06223595854644156\n",
      "train loss:0.09436690472920387\n",
      "train loss:0.1056136734636709\n",
      "train loss:0.03515529083419247\n",
      "train loss:0.08445842375547297\n",
      "train loss:0.054436231296012966\n",
      "train loss:0.0756021529600652\n",
      "train loss:0.057022560731534805\n",
      "train loss:0.03265874857148686\n",
      "train loss:0.05631237372729558\n",
      "train loss:0.1396180973787545\n",
      "train loss:0.1059898306031262\n",
      "train loss:0.17593292531338364\n",
      "train loss:0.1549051608697952\n",
      "train loss:0.037116467918765154\n",
      "train loss:0.06348015435353559\n",
      "train loss:0.0699749987880828\n",
      "train loss:0.040168747313229086\n",
      "train loss:0.07824972044170338\n",
      "train loss:0.10648249483885763\n",
      "train loss:0.06000497444818205\n",
      "train loss:0.08299665142212595\n",
      "train loss:0.10833105958652144\n",
      "train loss:0.07149443313128188\n",
      "train loss:0.0956599399084812\n",
      "train loss:0.08457587292523681\n",
      "train loss:0.04401065835254265\n",
      "train loss:0.11671362821783995\n",
      "train loss:0.09385717143007169\n",
      "train loss:0.04783725523871671\n",
      "train loss:0.2541157698917067\n",
      "train loss:0.036561914278817935\n",
      "train loss:0.11620321047351803\n",
      "train loss:0.16588007917312445\n",
      "train loss:0.022651041479286683\n",
      "train loss:0.06344677998443828\n",
      "train loss:0.09772120722095241\n",
      "train loss:0.0554611151340917\n",
      "train loss:0.09723143999777624\n",
      "train loss:0.16089050615731498\n",
      "train loss:0.06108199505951852\n",
      "train loss:0.05008064407760293\n",
      "train loss:0.0933482478694665\n",
      "train loss:0.07201814397146969\n",
      "train loss:0.09641945173337164\n",
      "train loss:0.0890838050321297\n",
      "train loss:0.024488063513805645\n",
      "train loss:0.021191552249280852\n",
      "train loss:0.14436181584411675\n",
      "train loss:0.0443536748780339\n",
      "train loss:0.05954797995716751\n",
      "train loss:0.04521106382017474\n",
      "train loss:0.06070683410665154\n",
      "train loss:0.04676858218502742\n",
      "train loss:0.12951164257875047\n",
      "train loss:0.10273218705658126\n",
      "train loss:0.031782459209967154\n",
      "train loss:0.06439331002337897\n",
      "train loss:0.0702811674974336\n",
      "train loss:0.08844460138028318\n",
      "train loss:0.19468846873366435\n",
      "train loss:0.06382388788130516\n",
      "train loss:0.049534000970062886\n",
      "train loss:0.04430517130926915\n",
      "train loss:0.07146595995590733\n",
      "train loss:0.054323228867915255\n",
      "train loss:0.06837315556188654\n",
      "train loss:0.0773590447887843\n",
      "train loss:0.061289435794218916\n",
      "train loss:0.15008408603349976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.13362855214979988\n",
      "train loss:0.0513882844116036\n",
      "train loss:0.1535748799465113\n",
      "train loss:0.08991416120946419\n",
      "train loss:0.09141762510175028\n",
      "train loss:0.07201397560206858\n",
      "train loss:0.04143745981381422\n",
      "train loss:0.0704518630481412\n",
      "train loss:0.13802497771932873\n",
      "train loss:0.03967873061222118\n",
      "train loss:0.12366391651050053\n",
      "train loss:0.16458642243403318\n",
      "train loss:0.02320200901979062\n",
      "train loss:0.14558250751119847\n",
      "train loss:0.0794143546666195\n",
      "train loss:0.09899587972918575\n",
      "train loss:0.10735609044228162\n",
      "train loss:0.049367528986967245\n",
      "train loss:0.07566893339097092\n",
      "train loss:0.0829541182061139\n",
      "train loss:0.08964221391437072\n",
      "train loss:0.03685178532050046\n",
      "train loss:0.07019838959029262\n",
      "train loss:0.1620760293945592\n",
      "train loss:0.05019783640217946\n",
      "train loss:0.1069571242533416\n",
      "train loss:0.10103635508370401\n",
      "train loss:0.041327392881814376\n",
      "train loss:0.04611046882546792\n",
      "train loss:0.0603182282790608\n",
      "train loss:0.027345228741498806\n",
      "train loss:0.07879133726467188\n",
      "train loss:0.061739836166843046\n",
      "train loss:0.13138704464694187\n",
      "train loss:0.08763995121209646\n",
      "train loss:0.07731493201300382\n",
      "train loss:0.05509019820699291\n",
      "train loss:0.09773442576935613\n",
      "train loss:0.08027875962330049\n",
      "train loss:0.03995877052491986\n",
      "train loss:0.07974988490311444\n",
      "train loss:0.12813678720662075\n",
      "train loss:0.12061127654759923\n",
      "train loss:0.04204204646802629\n",
      "train loss:0.05709592767376562\n",
      "train loss:0.1372943809005192\n",
      "train loss:0.053322370338701894\n",
      "train loss:0.0789314126485342\n",
      "train loss:0.07141955789827013\n",
      "train loss:0.1342689032341603\n",
      "train loss:0.08497899225743608\n",
      "train loss:0.10930562024756332\n",
      "train loss:0.02077136072140208\n",
      "train loss:0.02897148277136881\n",
      "train loss:0.1021205669750342\n",
      "train loss:0.08380008359190079\n",
      "train loss:0.06150050830650981\n",
      "train loss:0.17020806718516268\n",
      "train loss:0.06570160535359236\n",
      "train loss:0.09272755025062164\n",
      "train loss:0.10002584883718367\n",
      "train loss:0.13774900368166368\n",
      "train loss:0.05536797402701592\n",
      "train loss:0.034461385724234926\n",
      "train loss:0.03481450609111594\n",
      "train loss:0.14079435568558907\n",
      "train loss:0.05802476313783894\n",
      "train loss:0.10755846692322922\n",
      "train loss:0.1287485013121041\n",
      "train loss:0.09796496887839061\n",
      "train loss:0.049191022724405904\n",
      "train loss:0.12639276559946502\n",
      "train loss:0.03751841176147563\n",
      "train loss:0.1206367160985803\n",
      "train loss:0.07470881939481853\n",
      "train loss:0.05874317811399017\n",
      "train loss:0.0846316896138137\n",
      "train loss:0.09010964123170546\n",
      "train loss:0.033192197951882\n",
      "train loss:0.061926340123025864\n",
      "train loss:0.10677270436611103\n",
      "train loss:0.08888720019270205\n",
      "train loss:0.02612913756642335\n",
      "train loss:0.04331061226871669\n",
      "train loss:0.04042908065627835\n",
      "train loss:0.1373258722810586\n",
      "train loss:0.12218378068159456\n",
      "train loss:0.08619902116892271\n",
      "train loss:0.11758722755217688\n",
      "train loss:0.023124863217749245\n",
      "train loss:0.0747597673971123\n",
      "train loss:0.020786600833482133\n",
      "train loss:0.04430316381320739\n",
      "train loss:0.0758903167363355\n",
      "train loss:0.04089046130625031\n",
      "train loss:0.11048154349738111\n",
      "train loss:0.035693181873106015\n",
      "train loss:0.06926134696545894\n",
      "train loss:0.08997526081343839\n",
      "train loss:0.06841845041908307\n",
      "train loss:0.09624521488284606\n",
      "train loss:0.057556930826340474\n",
      "train loss:0.05135508894943683\n",
      "train loss:0.13090066753795418\n",
      "train loss:0.049431493714185974\n",
      "train loss:0.0410912752353435\n",
      "train loss:0.13624184628777078\n",
      "train loss:0.19061399440641005\n",
      "train loss:0.16058927468105433\n",
      "train loss:0.03798964323593116\n",
      "train loss:0.08455971961844906\n",
      "train loss:0.06374546856236733\n",
      "train loss:0.19600633883251914\n",
      "train loss:0.03572947593622996\n",
      "train loss:0.053906911347627415\n",
      "train loss:0.028583023091682324\n",
      "train loss:0.14904828039577822\n",
      "train loss:0.057124990710631145\n",
      "train loss:0.0615912009009576\n",
      "train loss:0.058079024727208474\n",
      "train loss:0.03124904446247044\n",
      "train loss:0.0751440495524163\n",
      "train loss:0.07547619665703849\n",
      "train loss:0.02783662149125821\n",
      "train loss:0.07504088411007817\n",
      "train loss:0.14980520654932505\n",
      "train loss:0.08763446609781642\n",
      "train loss:0.03556545727688442\n",
      "train loss:0.0771220022195123\n",
      "train loss:0.031962152994151005\n",
      "train loss:0.08172053106267643\n",
      "train loss:0.029919155737979753\n",
      "train loss:0.11086568258628413\n",
      "train loss:0.03800425822099546\n",
      "train loss:0.053092889733737145\n",
      "train loss:0.10013078875945017\n",
      "train loss:0.06998849612305919\n",
      "train loss:0.08908729112867995\n",
      "train loss:0.06708483013049199\n",
      "train loss:0.0640502633605156\n",
      "train loss:0.05977307061316819\n",
      "train loss:0.040534208292228834\n",
      "train loss:0.034542566079777924\n",
      "train loss:0.057125205333395844\n",
      "train loss:0.12653198454285206\n",
      "train loss:0.048504171861306344\n",
      "train loss:0.05466092827670388\n",
      "train loss:0.07383509383230999\n",
      "train loss:0.07757935142063742\n",
      "train loss:0.031315736970583714\n",
      "train loss:0.017264755032699558\n",
      "train loss:0.06109384705540957\n",
      "train loss:0.039704593055392916\n",
      "train loss:0.14228476582910665\n",
      "train loss:0.06821254748756843\n",
      "train loss:0.053205444298258166\n",
      "train loss:0.07443498190591852\n",
      "train loss:0.06460938601782784\n",
      "train loss:0.10899593230464505\n",
      "train loss:0.052854688719598635\n",
      "train loss:0.043870918333098\n",
      "train loss:0.07920741414373694\n",
      "train loss:0.030086801948905867\n",
      "train loss:0.08100508498894722\n",
      "train loss:0.08452341885076815\n",
      "train loss:0.05658380021470224\n",
      "train loss:0.046816382662241744\n",
      "train loss:0.03756352070345837\n",
      "train loss:0.07861426706692579\n",
      "train loss:0.06982331963753084\n",
      "train loss:0.06804819093706238\n",
      "train loss:0.13285891928674143\n",
      "train loss:0.03294163070362981\n",
      "train loss:0.11502103182055\n",
      "train loss:0.04675086894485813\n",
      "train loss:0.17277584688814418\n",
      "train loss:0.12354581761778795\n",
      "train loss:0.17791261115104046\n",
      "train loss:0.044057029341088266\n",
      "train loss:0.033787088982894384\n",
      "train loss:0.022934785506433023\n",
      "train loss:0.04811363973626314\n",
      "train loss:0.035266974379204036\n",
      "train loss:0.12528411105778875\n",
      "train loss:0.11029389634908213\n",
      "train loss:0.07007873500530977\n",
      "train loss:0.17621670110581056\n",
      "train loss:0.04235977024050818\n",
      "train loss:0.05293802653794002\n",
      "train loss:0.04868505496355003\n",
      "train loss:0.0637293097856538\n",
      "train loss:0.034380387409393275\n",
      "train loss:0.0913387409483638\n",
      "train loss:0.18457218368244133\n",
      "train loss:0.1120527057907439\n",
      "train loss:0.07254103897942044\n",
      "train loss:0.057084767751438996\n",
      "train loss:0.046290377007151946\n",
      "train loss:0.17031921051595778\n",
      "train loss:0.06276602559863119\n",
      "train loss:0.029082790911615312\n",
      "train loss:0.10544887620867069\n",
      "train loss:0.032513146342208595\n",
      "train loss:0.09174187206705259\n",
      "train loss:0.05402420031077773\n",
      "train loss:0.06258114515963736\n",
      "train loss:0.048623095102578964\n",
      "train loss:0.09342994750129914\n",
      "train loss:0.09483944042960131\n",
      "train loss:0.02908959618544233\n",
      "train loss:0.0304528107354522\n",
      "train loss:0.03139238851936636\n",
      "train loss:0.04777823565033392\n",
      "train loss:0.09566502074041304\n",
      "train loss:0.02190211418080528\n",
      "train loss:0.0803977691651652\n",
      "train loss:0.09057970863181605\n",
      "train loss:0.09283158836359169\n",
      "train loss:0.035152015354424124\n",
      "train loss:0.030737523199122197\n",
      "train loss:0.044008913708036855\n",
      "train loss:0.041821415860271466\n",
      "train loss:0.07962658776675985\n",
      "train loss:0.054822451529811786\n",
      "train loss:0.15924963000256395\n",
      "train loss:0.09818100147211789\n",
      "train loss:0.05836670651289002\n",
      "train loss:0.10351873879795104\n",
      "train loss:0.14401786926481505\n",
      "train loss:0.10978498321842016\n",
      "train loss:0.03526602529319305\n",
      "train loss:0.028524686866534456\n",
      "train loss:0.17887000100072195\n",
      "train loss:0.031859031114350296\n",
      "train loss:0.10984239970144659\n",
      "train loss:0.07807431945471087\n",
      "train loss:0.027520036181728096\n",
      "train loss:0.03351028582565698\n",
      "train loss:0.06688363088078042\n",
      "train loss:0.04712141806281465\n",
      "train loss:0.016515472237358986\n",
      "train loss:0.024545877691057757\n",
      "train loss:0.06573479459658235\n",
      "train loss:0.186301734431967\n",
      "train loss:0.03422014605902118\n",
      "train loss:0.12417534555347422\n",
      "train loss:0.04070196087116231\n",
      "train loss:0.14260441368638677\n",
      "train loss:0.10223256937443702\n",
      "train loss:0.01922322595983865\n",
      "train loss:0.06554959930225472\n",
      "train loss:0.07078216398390035\n",
      "train loss:0.0769733122525038\n",
      "train loss:0.052225887948601286\n",
      "train loss:0.09487103235549427\n",
      "train loss:0.07447470378821006\n",
      "train loss:0.036462236468616994\n",
      "train loss:0.05720869392221196\n",
      "train loss:0.0792156968710625\n",
      "train loss:0.050697859965093954\n",
      "train loss:0.058056466127035564\n",
      "train loss:0.10113535324416346\n",
      "train loss:0.05488896820412764\n",
      "train loss:0.06032126522331123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.04419199389189119\n",
      "train loss:0.1191720874471126\n",
      "train loss:0.026357025722170274\n",
      "train loss:0.1489577143921896\n",
      "train loss:0.15774978551175456\n",
      "train loss:0.017498871873765153\n",
      "train loss:0.051343395827462765\n",
      "train loss:0.05344833817717695\n",
      "train loss:0.09971240415784349\n",
      "train loss:0.05678444194674051\n",
      "train loss:0.053012418282672724\n",
      "train loss:0.08483668585883054\n",
      "train loss:0.06825373425725056\n",
      "train loss:0.022872867836705793\n",
      "train loss:0.09484893180889524\n",
      "train loss:0.19302115714899196\n",
      "train loss:0.03021142064576055\n",
      "train loss:0.03858509636403204\n",
      "train loss:0.08768247420002769\n",
      "train loss:0.0933940165691162\n",
      "train loss:0.04414371940511991\n",
      "train loss:0.08428982408411974\n",
      "train loss:0.03002604445932257\n",
      "train loss:0.07323495410779354\n",
      "train loss:0.0260813838278144\n",
      "train loss:0.08227172505302698\n",
      "train loss:0.08745107590392032\n",
      "train loss:0.0324697975703097\n",
      "train loss:0.04110580774698371\n",
      "train loss:0.12375188946598058\n",
      "train loss:0.08726078580980687\n",
      "train loss:0.03792921257094947\n",
      "train loss:0.034761708429459\n",
      "train loss:0.05476774901265531\n",
      "train loss:0.015349024359429513\n",
      "train loss:0.0807281335258418\n",
      "train loss:0.09995062398065581\n",
      "train loss:0.022740219276691093\n",
      "train loss:0.07203020941668457\n",
      "train loss:0.025166877901793866\n",
      "train loss:0.03573162540228146\n",
      "train loss:0.033235581650723316\n",
      "train loss:0.009140959231949474\n",
      "train loss:0.04198898562080904\n",
      "train loss:0.05153403868942005\n",
      "train loss:0.061795983898111535\n",
      "train loss:0.14702789427873345\n",
      "train loss:0.08072344610768639\n",
      "train loss:0.06552772654262169\n",
      "train loss:0.06699612446328716\n",
      "train loss:0.06924110325291047\n",
      "train loss:0.1098731397005842\n",
      "train loss:0.09841856015856948\n",
      "train loss:0.017994150494059388\n",
      "train loss:0.039141574096326216\n",
      "train loss:0.07114079260262926\n",
      "train loss:0.02369891194676403\n",
      "train loss:0.03389161120157081\n",
      "train loss:0.06540141897223309\n",
      "train loss:0.13618750107346853\n",
      "train loss:0.038785435878016264\n",
      "train loss:0.07756833082771726\n",
      "train loss:0.03138322509200748\n",
      "train loss:0.0851898534176457\n",
      "train loss:0.0714928436431647\n",
      "train loss:0.1256936725391976\n",
      "train loss:0.11324545739110357\n",
      "train loss:0.01646268913672527\n",
      "train loss:0.021560257415530488\n",
      "train loss:0.12158071864155538\n",
      "train loss:0.14270258501648342\n",
      "train loss:0.06221563809956689\n",
      "train loss:0.015428480091909821\n",
      "train loss:0.0884618397371458\n",
      "train loss:0.055358519842069354\n",
      "train loss:0.03453380531492736\n",
      "train loss:0.13152572143904534\n",
      "train loss:0.0368470475515779\n",
      "train loss:0.026044531206915945\n",
      "train loss:0.12455453549804912\n",
      "train loss:0.053648693488099315\n",
      "train loss:0.04272189903592495\n",
      "train loss:0.07419100857753418\n",
      "train loss:0.04616536712063014\n",
      "train loss:0.03185892782094802\n",
      "train loss:0.024718731292053663\n",
      "train loss:0.09702351114233249\n",
      "train loss:0.042500495117690745\n",
      "train loss:0.0273755980819436\n",
      "train loss:0.06460196150967389\n",
      "train loss:0.0315147488296896\n",
      "train loss:0.1291793939658939\n",
      "train loss:0.11096912846682351\n",
      "train loss:0.10353603847420859\n",
      "train loss:0.04206897208899917\n",
      "train loss:0.14418738126040684\n",
      "train loss:0.03444029916136687\n",
      "train loss:0.047635184223398096\n",
      "train loss:0.05188099562335893\n",
      "train loss:0.08085643257074832\n",
      "train loss:0.09835066918929898\n",
      "train loss:0.050111494659745875\n",
      "train loss:0.035732393705819154\n",
      "train loss:0.021943788511741766\n",
      "train loss:0.07469143938097816\n",
      "train loss:0.05900876903073898\n",
      "train loss:0.08615678450042359\n",
      "train loss:0.07177277554812962\n",
      "train loss:0.031016965036731597\n",
      "train loss:0.03504799831967294\n",
      "train loss:0.029879944644184267\n",
      "train loss:0.03379273483166752\n",
      "train loss:0.027452176211504687\n",
      "train loss:0.027304119261695993\n",
      "train loss:0.03980404337004042\n",
      "train loss:0.019183485988764876\n",
      "train loss:0.07129138243309356\n",
      "train loss:0.09210352309575635\n",
      "train loss:0.01502411688989248\n",
      "train loss:0.10618020165951453\n",
      "train loss:0.012994562072392619\n",
      "train loss:0.0533300543555395\n",
      "train loss:0.12299505223780254\n",
      "train loss:0.014696316245771217\n",
      "train loss:0.046567105733116614\n",
      "train loss:0.03579211241335819\n",
      "train loss:0.04576820886534997\n",
      "train loss:0.042277965846738035\n",
      "train loss:0.04180238589200576\n",
      "train loss:0.04068727913140081\n",
      "train loss:0.055057230198951895\n",
      "train loss:0.07096855133408252\n",
      "train loss:0.05895868740876055\n",
      "train loss:0.027618000323106445\n",
      "train loss:0.04469071428926563\n",
      "train loss:0.03512565425441823\n",
      "train loss:0.08849002743021242\n",
      "=== epoch:3, train acc:0.971, test acc:0.973 ===\n",
      "train loss:0.07153111180429458\n",
      "train loss:0.03107608467674711\n",
      "train loss:0.06187270256449804\n",
      "train loss:0.03525538079987864\n",
      "train loss:0.03772173196734596\n",
      "train loss:0.04846833672554606\n",
      "train loss:0.061835903539947126\n",
      "train loss:0.059226863134535554\n",
      "train loss:0.06136139600614823\n",
      "train loss:0.048391268423648964\n",
      "train loss:0.04047390622620921\n",
      "train loss:0.05100668413211608\n",
      "train loss:0.02298602603885043\n",
      "train loss:0.02631515146812355\n",
      "train loss:0.033903214525394874\n",
      "train loss:0.03412099287222992\n",
      "train loss:0.014267650912917847\n",
      "train loss:0.043122576186015144\n",
      "train loss:0.029198323698823022\n",
      "train loss:0.029412198446341666\n",
      "train loss:0.0395626474286966\n",
      "train loss:0.09160626841970085\n",
      "train loss:0.036261312369860334\n",
      "train loss:0.04330258369133136\n",
      "train loss:0.04072656704168831\n",
      "train loss:0.05769912970638152\n",
      "train loss:0.10977107983088902\n",
      "train loss:0.08151521765477339\n",
      "train loss:0.034710486811588476\n",
      "train loss:0.017997484201168132\n",
      "train loss:0.05141132022578345\n",
      "train loss:0.01998103152642716\n",
      "train loss:0.051887187048572335\n",
      "train loss:0.027533398293845587\n",
      "train loss:0.09270201511846293\n",
      "train loss:0.04706600228029425\n",
      "train loss:0.027024071266575675\n",
      "train loss:0.02582121193254999\n",
      "train loss:0.03207048149149064\n",
      "train loss:0.0744863987778856\n",
      "train loss:0.08283674780992176\n",
      "train loss:0.02272523083462864\n",
      "train loss:0.014764608416632526\n",
      "train loss:0.03750749748081865\n",
      "train loss:0.009094134618607757\n",
      "train loss:0.06408170398619137\n",
      "train loss:0.1022910147053832\n",
      "train loss:0.052935116573820204\n",
      "train loss:0.04962657404568417\n",
      "train loss:0.0809706055871497\n",
      "train loss:0.1268623856835465\n",
      "train loss:0.01210051957843129\n",
      "train loss:0.1377633249970039\n",
      "train loss:0.024922978588192795\n",
      "train loss:0.041662230983093386\n",
      "train loss:0.049838354116866344\n",
      "train loss:0.06285877790714295\n",
      "train loss:0.0301374401969379\n",
      "train loss:0.06986187627437662\n",
      "train loss:0.03887722063516867\n",
      "train loss:0.033590436360839575\n",
      "train loss:0.06779784144595415\n",
      "train loss:0.05262255111322992\n",
      "train loss:0.023920218643661433\n",
      "train loss:0.04591897243292668\n",
      "train loss:0.05608050502285652\n",
      "train loss:0.05533051783269845\n",
      "train loss:0.0489104589617186\n",
      "train loss:0.03942349782662501\n",
      "train loss:0.027266649492700808\n",
      "train loss:0.06371062133037864\n",
      "train loss:0.02955217795115989\n",
      "train loss:0.041278676290497994\n",
      "train loss:0.058364328589514354\n",
      "train loss:0.044538930025158595\n",
      "train loss:0.021500498711726757\n",
      "train loss:0.03674007909572793\n",
      "train loss:0.03459242082620913\n",
      "train loss:0.018518931502013405\n",
      "train loss:0.025060478277943162\n",
      "train loss:0.012743454956279137\n",
      "train loss:0.07752864935686994\n",
      "train loss:0.1000363178579248\n",
      "train loss:0.12215477169224372\n",
      "train loss:0.11609396776661988\n",
      "train loss:0.044245922661144285\n",
      "train loss:0.10709567524964315\n",
      "train loss:0.05790223988589953\n",
      "train loss:0.06558203882978937\n",
      "train loss:0.08125908344616796\n",
      "train loss:0.15155209917568035\n",
      "train loss:0.07850661102382542\n",
      "train loss:0.03149151958649181\n",
      "train loss:0.027633456024681546\n",
      "train loss:0.02702608812394847\n",
      "train loss:0.05379231967157528\n",
      "train loss:0.039410215183085046\n",
      "train loss:0.037414634495705396\n",
      "train loss:0.016415411252715617\n",
      "train loss:0.03701095317080575\n",
      "train loss:0.17736898026803438\n",
      "train loss:0.057549133982033436\n",
      "train loss:0.028976662452176085\n",
      "train loss:0.0623470307944899\n",
      "train loss:0.02444527387837907\n",
      "train loss:0.03922063926631521\n",
      "train loss:0.03947591644967787\n",
      "train loss:0.046640991690958596\n",
      "train loss:0.10121652387467833\n",
      "train loss:0.03844837634819615\n",
      "train loss:0.031654950230740636\n",
      "train loss:0.03499805061725758\n",
      "train loss:0.025978913166541124\n",
      "train loss:0.043564577759855956\n",
      "train loss:0.09161827030583929\n",
      "train loss:0.03618987956806845\n",
      "train loss:0.0658104358565316\n",
      "train loss:0.04833103882256069\n",
      "train loss:0.022207555963786582\n",
      "train loss:0.02898542580917622\n",
      "train loss:0.05281615924014094\n",
      "train loss:0.12565258061214687\n",
      "train loss:0.05902826306098745\n",
      "train loss:0.05485601814632777\n",
      "train loss:0.08164425579484251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.018981458140125432\n",
      "train loss:0.10963423678488547\n",
      "train loss:0.029386938153832656\n",
      "train loss:0.10326489057554314\n",
      "train loss:0.026921856309057933\n",
      "train loss:0.042905396156564454\n",
      "train loss:0.03937412051826605\n",
      "train loss:0.16758422212130192\n",
      "train loss:0.04156442436693859\n",
      "train loss:0.055602846962567794\n",
      "train loss:0.05799057887935868\n",
      "train loss:0.017996049450718178\n",
      "train loss:0.060489862170061935\n",
      "train loss:0.016053696746913298\n",
      "train loss:0.05413366296210534\n",
      "train loss:0.0639240024792479\n",
      "train loss:0.0805107861461755\n",
      "train loss:0.038206452202647914\n",
      "train loss:0.048595737031089555\n",
      "train loss:0.039927551268758736\n",
      "train loss:0.13488675547506537\n",
      "train loss:0.051277297147716144\n",
      "train loss:0.018428121180437424\n",
      "train loss:0.024751822934638103\n",
      "train loss:0.03226905171260226\n",
      "train loss:0.034427049921018554\n",
      "train loss:0.04239438753043775\n",
      "train loss:0.03249998861442562\n",
      "train loss:0.0810792712134467\n",
      "train loss:0.06973837794585826\n",
      "train loss:0.026162042708722594\n",
      "train loss:0.016756432026087512\n",
      "train loss:0.01528268958838138\n",
      "train loss:0.12098813933468287\n",
      "train loss:0.029805128970982156\n",
      "train loss:0.0808255655185259\n",
      "train loss:0.10875618243226226\n",
      "train loss:0.03760747774342397\n",
      "train loss:0.034461962375669036\n",
      "train loss:0.1143157632941408\n",
      "train loss:0.06072174983626308\n",
      "train loss:0.04384279036424047\n",
      "train loss:0.03623041541972911\n",
      "train loss:0.02824891548506005\n",
      "train loss:0.025327844390767896\n",
      "train loss:0.0845950674866417\n",
      "train loss:0.06319631047513592\n",
      "train loss:0.038847386628149\n",
      "train loss:0.019935775816866355\n",
      "train loss:0.05837033004507349\n",
      "train loss:0.025773098881277243\n",
      "train loss:0.06407106200547986\n",
      "train loss:0.09874545486881116\n",
      "train loss:0.022996018054124535\n",
      "train loss:0.057062164232392645\n",
      "train loss:0.13152928182839602\n",
      "train loss:0.09279932544009684\n",
      "train loss:0.11849766584705577\n",
      "train loss:0.04748215003905739\n",
      "train loss:0.046585096717115436\n",
      "train loss:0.06555816549482928\n",
      "train loss:0.05465975776922541\n",
      "train loss:0.05020586839072747\n",
      "train loss:0.04389277414886458\n",
      "train loss:0.06756321959184612\n",
      "train loss:0.051126098398778935\n",
      "train loss:0.055615584787648366\n",
      "train loss:0.04371940379657512\n",
      "train loss:0.021169353319213075\n",
      "train loss:0.05930625507791122\n",
      "train loss:0.021033890539458637\n",
      "train loss:0.040157046932817145\n",
      "train loss:0.023992513347804965\n",
      "train loss:0.04190376760445101\n",
      "train loss:0.05492910791153101\n",
      "train loss:0.08067780735565508\n",
      "train loss:0.046470951913600594\n",
      "train loss:0.050777197159677524\n",
      "train loss:0.023451511459526963\n",
      "train loss:0.025536442455761428\n",
      "train loss:0.03607530652284338\n",
      "train loss:0.04405642871454459\n",
      "train loss:0.06452534774395975\n",
      "train loss:0.01349346725904613\n",
      "train loss:0.13797186046408658\n",
      "train loss:0.02784744120147313\n",
      "train loss:0.07533940004914197\n",
      "train loss:0.07800111423828456\n",
      "train loss:0.0574743644806188\n",
      "train loss:0.05747179475484221\n",
      "train loss:0.061195355436967386\n",
      "train loss:0.09060291409025444\n",
      "train loss:0.08043939589481046\n",
      "train loss:0.09303225609574804\n",
      "train loss:0.08714224064721911\n",
      "train loss:0.09170346150670555\n",
      "train loss:0.03927966221610488\n",
      "train loss:0.008127896819360894\n",
      "train loss:0.05753821931393833\n",
      "train loss:0.023380781683982724\n",
      "train loss:0.09627951740811479\n",
      "train loss:0.018411516351826605\n",
      "train loss:0.024049463180317893\n",
      "train loss:0.011191890795875315\n",
      "train loss:0.1072924507747734\n",
      "train loss:0.035419913976105104\n",
      "train loss:0.08993389747799733\n",
      "train loss:0.0703990076690124\n",
      "train loss:0.11371827406246922\n",
      "train loss:0.03912524138975222\n",
      "train loss:0.013845483100342306\n",
      "train loss:0.021373878782597645\n",
      "train loss:0.03845393257495894\n",
      "train loss:0.023896284433877854\n",
      "train loss:0.023542130606737755\n",
      "train loss:0.019374050664148455\n",
      "train loss:0.022000569439858824\n",
      "train loss:0.02572128989451481\n",
      "train loss:0.05017335866798983\n",
      "train loss:0.02450848563655557\n",
      "train loss:0.020494851036518217\n",
      "train loss:0.06521357303970715\n",
      "train loss:0.030300262773871586\n",
      "train loss:0.04058592691640159\n",
      "train loss:0.03648469223765456\n",
      "train loss:0.02265098851437938\n",
      "train loss:0.1186317039223245\n",
      "train loss:0.05263755324941814\n",
      "train loss:0.06984620421907783\n",
      "train loss:0.044652055436424004\n",
      "train loss:0.02725495108504357\n",
      "train loss:0.01888310504669295\n",
      "train loss:0.09529945646297178\n",
      "train loss:0.03685288046543044\n",
      "train loss:0.036605145601843095\n",
      "train loss:0.09457480973391195\n",
      "train loss:0.019662837926913434\n",
      "train loss:0.07074200823525316\n",
      "train loss:0.021606446523659843\n",
      "train loss:0.02836426862311616\n",
      "train loss:0.03755944038576303\n",
      "train loss:0.022152951629112426\n",
      "train loss:0.036020187916190334\n",
      "train loss:0.018296257580786512\n",
      "train loss:0.054375635280256754\n",
      "train loss:0.03565068378568363\n",
      "train loss:0.14340167735262258\n",
      "train loss:0.049791345968452444\n",
      "train loss:0.1181998098525246\n",
      "train loss:0.009835194665888012\n",
      "train loss:0.013617262493924\n",
      "train loss:0.05999634287205822\n",
      "train loss:0.03764063188463295\n",
      "train loss:0.024505527764664765\n",
      "train loss:0.04647141700897643\n",
      "train loss:0.01279565636969183\n",
      "train loss:0.07877417995134693\n",
      "train loss:0.025577711535896285\n",
      "train loss:0.013477526300691895\n",
      "train loss:0.07064885749923513\n",
      "train loss:0.05902732002230622\n",
      "train loss:0.016963093119458757\n",
      "train loss:0.041128219745717114\n",
      "train loss:0.07195080604148327\n",
      "train loss:0.04175849569627733\n",
      "train loss:0.12345140397364598\n",
      "train loss:0.03335863330052218\n",
      "train loss:0.04606548175103237\n",
      "train loss:0.13588499471835822\n",
      "train loss:0.05653870696739947\n",
      "train loss:0.027464651364767296\n",
      "train loss:0.10351991476661489\n",
      "train loss:0.01989327353203896\n",
      "train loss:0.017899337924049012\n",
      "train loss:0.08472682120581072\n",
      "train loss:0.05200672837367813\n",
      "train loss:0.07168785111958696\n",
      "train loss:0.06006916505887438\n",
      "train loss:0.02992365251075188\n",
      "train loss:0.03073736903179837\n",
      "train loss:0.07634749672590867\n",
      "train loss:0.013837932418595782\n",
      "train loss:0.047945283929507546\n",
      "train loss:0.05892292034977746\n",
      "train loss:0.05918310140737993\n",
      "train loss:0.04121434501876808\n",
      "train loss:0.0375312069548835\n",
      "train loss:0.03482451908321734\n",
      "train loss:0.0160889248171342\n",
      "train loss:0.06135954294644399\n",
      "train loss:0.030574272023322288\n",
      "train loss:0.022857295978459296\n",
      "train loss:0.11160196408468162\n",
      "train loss:0.04213425540307957\n",
      "train loss:0.024248109339982914\n",
      "train loss:0.03286536566562553\n",
      "train loss:0.0631573849964318\n",
      "train loss:0.016931293103323343\n",
      "train loss:0.014848247978808517\n",
      "train loss:0.03697976033009284\n",
      "train loss:0.0931369586165244\n",
      "train loss:0.041334285284134485\n",
      "train loss:0.04428923875807356\n",
      "train loss:0.05571660236491572\n",
      "train loss:0.040012659416278885\n",
      "train loss:0.022606127004679538\n",
      "train loss:0.046625638133781996\n",
      "train loss:0.1637809724694821\n",
      "train loss:0.04890435258438997\n",
      "train loss:0.05772161670460092\n",
      "train loss:0.03571639399489349\n",
      "train loss:0.03455879175685319\n",
      "train loss:0.05680196807743615\n",
      "train loss:0.05315976436828321\n",
      "train loss:0.024354095739608023\n",
      "train loss:0.017930502828085112\n",
      "train loss:0.05217780983659399\n",
      "train loss:0.006533332661142092\n",
      "train loss:0.006019102638591995\n",
      "train loss:0.09722681867728979\n",
      "train loss:0.028449374445151464\n",
      "train loss:0.0869229717373385\n",
      "train loss:0.030166682875352114\n",
      "train loss:0.0893429537793678\n",
      "train loss:0.006092721544510463\n",
      "train loss:0.01973521742442424\n",
      "train loss:0.009851550771731495\n",
      "train loss:0.11969285347490251\n",
      "train loss:0.07580364505718577\n",
      "train loss:0.0734261875889652\n",
      "train loss:0.028432558076213522\n",
      "train loss:0.06439731889288809\n",
      "train loss:0.025735032837808855\n",
      "train loss:0.05373763903663376\n",
      "train loss:0.047023385056303726\n",
      "train loss:0.050958956804627274\n",
      "train loss:0.07098209788292593\n",
      "train loss:0.020430783849154276\n",
      "train loss:0.13679201014768233\n",
      "train loss:0.07044475852749703\n",
      "train loss:0.04221247669566546\n",
      "train loss:0.04361788641687712\n",
      "train loss:0.05017491576065607\n",
      "train loss:0.09260234756017344\n",
      "train loss:0.03365353328042709\n",
      "train loss:0.012024676845759655\n",
      "train loss:0.00876553733237183\n",
      "train loss:0.022388986971165127\n",
      "train loss:0.03961214914691144\n",
      "train loss:0.03734726321045426\n",
      "train loss:0.025189155082214296\n",
      "train loss:0.017694347933113367\n",
      "train loss:0.04275640673234289\n",
      "train loss:0.008449942102909173\n",
      "train loss:0.015351590266649142\n",
      "train loss:0.06261681620137349\n",
      "train loss:0.058550447025770475\n",
      "train loss:0.09532478648259808\n",
      "train loss:0.04173001165295404\n",
      "train loss:0.0386979836852174\n",
      "train loss:0.013977574483346102\n",
      "train loss:0.011220157887032406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0470147678418125\n",
      "train loss:0.03505881751245913\n",
      "train loss:0.02216284221661285\n",
      "train loss:0.023030853019835863\n",
      "train loss:0.050220943827441286\n",
      "train loss:0.08057025001360495\n",
      "train loss:0.015502721591837791\n",
      "train loss:0.07574477078457838\n",
      "train loss:0.0686485614794673\n",
      "train loss:0.04629692024959371\n",
      "train loss:0.021464739432126723\n",
      "train loss:0.08599114185194362\n",
      "train loss:0.0141440357900076\n",
      "train loss:0.0556311543369408\n",
      "train loss:0.022538256415562386\n",
      "train loss:0.026960954636201417\n",
      "train loss:0.06865532321679735\n",
      "train loss:0.08833418958378102\n",
      "train loss:0.06836187062583174\n",
      "train loss:0.011830156647498414\n",
      "train loss:0.06383488615457901\n",
      "train loss:0.07634473362152028\n",
      "train loss:0.011780440336534003\n",
      "train loss:0.047618242934868195\n",
      "train loss:0.02837304911845322\n",
      "train loss:0.027358532693773897\n",
      "train loss:0.08749179843884215\n",
      "train loss:0.02944262923491641\n",
      "train loss:0.05653862819138713\n",
      "train loss:0.046327757705784366\n",
      "train loss:0.024967299985616257\n",
      "train loss:0.032854021104680185\n",
      "train loss:0.11389912507156633\n",
      "train loss:0.013581745734076965\n",
      "train loss:0.015942072006825174\n",
      "train loss:0.0778037187674799\n",
      "train loss:0.043902003201908\n",
      "train loss:0.11983760544043807\n",
      "train loss:0.04303556465608531\n",
      "train loss:0.06261102921673588\n",
      "train loss:0.033155407730572815\n",
      "train loss:0.06607521284375749\n",
      "train loss:0.04485584936768097\n",
      "train loss:0.07541238726284633\n",
      "train loss:0.02304031532701818\n",
      "train loss:0.05541269055518216\n",
      "train loss:0.05955166311361891\n",
      "train loss:0.020558946847678037\n",
      "train loss:0.03083996166026934\n",
      "train loss:0.035014652844983875\n",
      "train loss:0.01574356229425689\n",
      "train loss:0.059569460218547574\n",
      "train loss:0.04612600790171219\n",
      "train loss:0.010800967700792108\n",
      "train loss:0.03230168827720242\n",
      "train loss:0.03865223438299452\n",
      "train loss:0.009082102100352797\n",
      "train loss:0.04079114081396368\n",
      "train loss:0.030815351586577163\n",
      "train loss:0.045732253140787237\n",
      "train loss:0.037549475407006726\n",
      "train loss:0.014901072106888678\n",
      "train loss:0.058909303860324454\n",
      "train loss:0.028490147500340145\n",
      "train loss:0.05426994550547325\n",
      "train loss:0.03587408040955395\n",
      "train loss:0.009905804719526899\n",
      "train loss:0.013334446660970434\n",
      "train loss:0.0920419593034996\n",
      "train loss:0.05758988345172259\n",
      "train loss:0.03239957716521828\n",
      "train loss:0.009504273950964752\n",
      "train loss:0.031178629267017796\n",
      "train loss:0.038502140416639165\n",
      "train loss:0.03955322941971681\n",
      "train loss:0.10278427498133742\n",
      "train loss:0.018203137506161426\n",
      "train loss:0.049494861725485756\n",
      "train loss:0.04722774568089005\n",
      "train loss:0.0269124787152882\n",
      "train loss:0.02441514675783081\n",
      "train loss:0.01381118343545935\n",
      "train loss:0.10205251755875251\n",
      "train loss:0.02682287195377267\n",
      "train loss:0.1391431955536319\n",
      "train loss:0.07589093798002097\n",
      "train loss:0.06595059455436549\n",
      "train loss:0.048519560992584046\n",
      "train loss:0.010356995278452453\n",
      "train loss:0.05820091747907111\n",
      "train loss:0.06955192752936405\n",
      "train loss:0.031381131209676935\n",
      "train loss:0.020997240359110297\n",
      "train loss:0.012956382472599155\n",
      "train loss:0.04777111274748874\n",
      "train loss:0.015070474186243396\n",
      "train loss:0.06811180353749952\n",
      "train loss:0.02948422065065608\n",
      "train loss:0.01892627167413334\n",
      "train loss:0.03546321748887976\n",
      "train loss:0.04300292452953001\n",
      "train loss:0.01967369153762222\n",
      "train loss:0.09141180633983208\n",
      "train loss:0.02034173941782694\n",
      "train loss:0.05652522549393597\n",
      "train loss:0.0502610616867632\n",
      "train loss:0.02198904186846908\n",
      "train loss:0.07006141548979675\n",
      "train loss:0.014332715619670516\n",
      "train loss:0.11320391493612714\n",
      "train loss:0.016661296799485324\n",
      "train loss:0.018256794322097952\n",
      "train loss:0.11167467755373923\n",
      "train loss:0.011432294488817355\n",
      "train loss:0.021121622786489994\n",
      "train loss:0.020250652397867316\n",
      "train loss:0.03694267095346917\n",
      "train loss:0.03757524997576582\n",
      "train loss:0.14650775416320777\n",
      "train loss:0.018248646824542695\n",
      "train loss:0.11758275649440227\n",
      "train loss:0.02595939347057035\n",
      "train loss:0.04882618665839247\n",
      "train loss:0.009497809928292382\n",
      "train loss:0.019386163252886283\n",
      "train loss:0.06696412924907472\n",
      "train loss:0.02886136611530679\n",
      "train loss:0.04998994057412645\n",
      "train loss:0.024965874564391435\n",
      "train loss:0.02242690328693683\n",
      "train loss:0.010140744370761201\n",
      "train loss:0.026275726067928683\n",
      "train loss:0.055717446238249015\n",
      "train loss:0.02469673611624975\n",
      "train loss:0.10899577164837428\n",
      "train loss:0.015444025994314376\n",
      "train loss:0.03743757027936612\n",
      "train loss:0.02846962877730161\n",
      "train loss:0.019332070102559565\n",
      "train loss:0.0524461848316569\n",
      "train loss:0.024431628261028883\n",
      "train loss:0.049012691198304384\n",
      "train loss:0.03667195569675621\n",
      "train loss:0.01702927191632916\n",
      "train loss:0.16614500403255922\n",
      "train loss:0.10092795359730317\n",
      "train loss:0.08087009159358298\n",
      "train loss:0.03229357577756047\n",
      "train loss:0.1075153310320162\n",
      "train loss:0.09884134969840214\n",
      "train loss:0.02095473025506292\n",
      "train loss:0.03524561100931558\n",
      "train loss:0.03326883897218627\n",
      "train loss:0.08113959205202555\n",
      "train loss:0.037712375716338606\n",
      "train loss:0.07835685114430693\n",
      "train loss:0.04989373921287894\n",
      "train loss:0.028921933314845775\n",
      "train loss:0.04762042569508638\n",
      "train loss:0.07928110854485708\n",
      "train loss:0.04263839814823247\n",
      "train loss:0.09066190306469617\n",
      "train loss:0.025757908977920532\n",
      "train loss:0.054193178924231325\n",
      "train loss:0.05495196478728131\n",
      "train loss:0.006929575057928343\n",
      "train loss:0.0526982048603655\n",
      "train loss:0.04454692870231565\n",
      "train loss:0.02620177484644615\n",
      "train loss:0.014844615042503187\n",
      "train loss:0.016364533444546817\n",
      "train loss:0.03534926084763779\n",
      "train loss:0.0864001711361965\n",
      "train loss:0.03710708515752336\n",
      "train loss:0.020763047447940684\n",
      "train loss:0.05768892928727709\n",
      "train loss:0.006223104611681038\n",
      "train loss:0.05659357019482952\n",
      "train loss:0.06667482618477073\n",
      "train loss:0.014368980401869829\n",
      "train loss:0.05402261974070962\n",
      "train loss:0.031110587475925388\n",
      "train loss:0.02172791678244628\n",
      "train loss:0.025423318339431816\n",
      "train loss:0.06351063397596259\n",
      "train loss:0.014724456142420723\n",
      "train loss:0.05060535276090215\n",
      "train loss:0.026091354119458114\n",
      "train loss:0.01994468611987353\n",
      "train loss:0.04356332782147478\n",
      "train loss:0.061988378500165545\n",
      "train loss:0.027591044778578166\n",
      "train loss:0.08334206805855794\n",
      "train loss:0.06815701010564695\n",
      "train loss:0.025513245787140454\n",
      "train loss:0.08214453701656009\n",
      "train loss:0.019844320458701624\n",
      "train loss:0.032613838661399705\n",
      "train loss:0.021791971747867386\n",
      "train loss:0.08513265704627827\n",
      "train loss:0.03833782433785381\n",
      "train loss:0.034048149916905156\n",
      "train loss:0.037510633849603944\n",
      "train loss:0.05158374303697246\n",
      "train loss:0.04473186477516977\n",
      "train loss:0.049025522955901686\n",
      "train loss:0.028922320778387613\n",
      "train loss:0.044677190202564734\n",
      "train loss:0.02478072136851082\n",
      "train loss:0.08458808762699144\n",
      "train loss:0.020752230799414077\n",
      "train loss:0.01672938030474542\n",
      "train loss:0.08411576181079208\n",
      "=== epoch:4, train acc:0.984, test acc:0.981 ===\n",
      "train loss:0.0246342334376342\n",
      "train loss:0.012380680432432612\n",
      "train loss:0.03177943132041424\n",
      "train loss:0.06875264386530494\n",
      "train loss:0.04823960699900284\n",
      "train loss:0.016261122158723364\n",
      "train loss:0.0856438691072967\n",
      "train loss:0.0206264505916332\n",
      "train loss:0.00941788443778927\n",
      "train loss:0.06317759282841949\n",
      "train loss:0.047155577889701046\n",
      "train loss:0.040634089178162476\n",
      "train loss:0.047267575145231285\n",
      "train loss:0.059807856759696666\n",
      "train loss:0.03128675981376729\n",
      "train loss:0.029203035192305493\n",
      "train loss:0.01331675780768689\n",
      "train loss:0.019081203523396734\n",
      "train loss:0.031098598420958235\n",
      "train loss:0.13597191661739444\n",
      "train loss:0.023574526490218246\n",
      "train loss:0.009065162813698313\n",
      "train loss:0.01843240999587995\n",
      "train loss:0.09876951504407876\n",
      "train loss:0.027808386301557433\n",
      "train loss:0.1222534198838112\n",
      "train loss:0.04923402437315033\n",
      "train loss:0.03769523644326989\n",
      "train loss:0.016671947966358652\n",
      "train loss:0.017539445858949315\n",
      "train loss:0.029882537898839403\n",
      "train loss:0.009353149697556245\n",
      "train loss:0.027386220763038933\n",
      "train loss:0.12852698344836677\n",
      "train loss:0.04912880918935967\n",
      "train loss:0.08066379356291659\n",
      "train loss:0.015407127187716991\n",
      "train loss:0.033313006575302104\n",
      "train loss:0.06761962391661759\n",
      "train loss:0.014088453956378207\n",
      "train loss:0.03836644312559457\n",
      "train loss:0.03601248510534067\n",
      "train loss:0.07875520651693646\n",
      "train loss:0.050287210037951974\n",
      "train loss:0.041628909561715076\n",
      "train loss:0.02863670636098612\n",
      "train loss:0.03545109690384312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.012098064328910996\n",
      "train loss:0.01347860662156108\n",
      "train loss:0.08694839612185114\n",
      "train loss:0.03542577411506299\n",
      "train loss:0.045508624277253974\n",
      "train loss:0.027321093319173526\n",
      "train loss:0.07739533995497196\n",
      "train loss:0.03354887101232406\n",
      "train loss:0.028235203452243843\n",
      "train loss:0.043605107463217746\n",
      "train loss:0.05680390112678852\n",
      "train loss:0.015591619472747342\n",
      "train loss:0.031203679596547497\n",
      "train loss:0.032772409928944715\n",
      "train loss:0.03434087838479185\n",
      "train loss:0.03673824851374954\n",
      "train loss:0.02397450452797144\n",
      "train loss:0.02253348075826838\n",
      "train loss:0.022854689271668813\n",
      "train loss:0.04148351389099816\n",
      "train loss:0.06888127725324625\n",
      "train loss:0.01669847264052375\n",
      "train loss:0.0408089222330592\n",
      "train loss:0.019036732878209284\n",
      "train loss:0.020122079002807963\n",
      "train loss:0.0074634568227649675\n",
      "train loss:0.09931619178430065\n",
      "train loss:0.034814165057034906\n",
      "train loss:0.017819307359793434\n",
      "train loss:0.023773312592602944\n",
      "train loss:0.07618563152266046\n",
      "train loss:0.047655954417928165\n",
      "train loss:0.10606090520734228\n",
      "train loss:0.02069977913767052\n",
      "train loss:0.06738411539511618\n",
      "train loss:0.019251867818200527\n",
      "train loss:0.01776336441653678\n",
      "train loss:0.056339043914528625\n",
      "train loss:0.13265484059486896\n",
      "train loss:0.020992901665494123\n",
      "train loss:0.019096312150626876\n",
      "train loss:0.014099825095518392\n",
      "train loss:0.13538927095314124\n",
      "train loss:0.05145132902586129\n",
      "train loss:0.03608044842967337\n",
      "train loss:0.027091232058370576\n",
      "train loss:0.03118420722506027\n",
      "train loss:0.05631702354048149\n",
      "train loss:0.01503352321122668\n",
      "train loss:0.028437000191688742\n",
      "train loss:0.04163196350892545\n",
      "train loss:0.11082893965851506\n",
      "train loss:0.05974380557798586\n",
      "train loss:0.07232359002115929\n",
      "train loss:0.013034309942282538\n",
      "train loss:0.028184633807197382\n",
      "train loss:0.064200366967678\n",
      "train loss:0.03199358952336975\n",
      "train loss:0.017571874266157545\n",
      "train loss:0.020566365332236672\n",
      "train loss:0.03915649243214327\n",
      "train loss:0.11615565516879807\n",
      "train loss:0.022165013047555533\n",
      "train loss:0.046705366230022465\n",
      "train loss:0.07674826538847261\n",
      "train loss:0.03154452623980555\n",
      "train loss:0.011852875089141736\n",
      "train loss:0.03745028826770911\n",
      "train loss:0.016696693207995623\n",
      "train loss:0.052045373945273206\n",
      "train loss:0.008151591515237177\n",
      "train loss:0.0663993851432176\n",
      "train loss:0.014085638458026031\n",
      "train loss:0.008211979074347812\n",
      "train loss:0.01404928932294569\n",
      "train loss:0.03487781399612247\n",
      "train loss:0.038646094118002225\n",
      "train loss:0.04834843870503714\n",
      "train loss:0.07406969697867866\n",
      "train loss:0.055163087899262345\n",
      "train loss:0.08036856924774101\n",
      "train loss:0.029247378247990872\n",
      "train loss:0.04157463240574765\n",
      "train loss:0.024009684456725345\n",
      "train loss:0.11037646843096467\n",
      "train loss:0.006790191129793069\n",
      "train loss:0.06906424624586179\n",
      "train loss:0.017332644596804156\n",
      "train loss:0.015124152241885833\n",
      "train loss:0.020218882470140854\n",
      "train loss:0.04634437867178482\n",
      "train loss:0.018139552876320884\n",
      "train loss:0.03023468842999132\n",
      "train loss:0.007263276481062517\n",
      "train loss:0.01894507152559728\n",
      "train loss:0.009510149839378292\n",
      "train loss:0.02868818257560239\n",
      "train loss:0.008656304406069269\n",
      "train loss:0.04382177369011711\n",
      "train loss:0.024008243139092725\n",
      "train loss:0.03584049110255169\n",
      "train loss:0.11207593483357085\n",
      "train loss:0.008686671329586617\n",
      "train loss:0.05232340391147711\n",
      "train loss:0.015794417920820564\n",
      "train loss:0.013964419510237625\n",
      "train loss:0.036137954716534325\n",
      "train loss:0.0867643005119832\n",
      "train loss:0.038465430800073544\n",
      "train loss:0.043101413394003155\n",
      "train loss:0.048782462030878826\n",
      "train loss:0.014100817579881767\n",
      "train loss:0.03642238310699125\n",
      "train loss:0.011679175383592408\n",
      "train loss:0.07351204799151043\n",
      "train loss:0.016402324922491843\n",
      "train loss:0.0391922026050556\n",
      "train loss:0.009886292054758453\n",
      "train loss:0.012236391625783962\n",
      "train loss:0.014479151998420424\n",
      "train loss:0.006770378629642521\n",
      "train loss:0.05057957940724055\n",
      "train loss:0.05979443888236537\n",
      "train loss:0.028537502679845162\n",
      "train loss:0.056499806485324565\n",
      "train loss:0.012954103163518589\n",
      "train loss:0.015829847047612092\n",
      "train loss:0.012835894276738273\n",
      "train loss:0.02552669958141554\n",
      "train loss:0.03384627509574643\n",
      "train loss:0.006567691117480516\n",
      "train loss:0.01713805925031873\n",
      "train loss:0.02303799034952986\n",
      "train loss:0.013900364131998147\n",
      "train loss:0.03612338261266815\n",
      "train loss:0.02427853798817777\n",
      "train loss:0.011536544814848025\n",
      "train loss:0.008520105284885449\n",
      "train loss:0.022615826684680256\n",
      "train loss:0.005030857085788047\n",
      "train loss:0.06077229193584365\n",
      "train loss:0.05321071293301064\n",
      "train loss:0.01588572801284495\n",
      "train loss:0.012302119619479513\n",
      "train loss:0.0652625663877182\n",
      "train loss:0.016548544951044995\n",
      "train loss:0.03860163879710336\n",
      "train loss:0.011873538811398441\n",
      "train loss:0.11524696446126531\n",
      "train loss:0.01210676188500961\n",
      "train loss:0.008263557882151292\n",
      "train loss:0.04443309138814427\n",
      "train loss:0.047431207066673656\n",
      "train loss:0.06877289672415686\n",
      "train loss:0.03415114471959615\n",
      "train loss:0.11275479340691817\n",
      "train loss:0.015627944136929396\n",
      "train loss:0.009241648106581181\n",
      "train loss:0.005804810541708646\n",
      "train loss:0.02568143446971519\n",
      "train loss:0.009979722903013634\n",
      "train loss:0.11522164637423211\n",
      "train loss:0.07489112927922525\n",
      "train loss:0.011002836516153918\n",
      "train loss:0.07171196681438438\n",
      "train loss:0.03966916379532683\n",
      "train loss:0.011514452658524885\n",
      "train loss:0.016207886921010804\n",
      "train loss:0.03794018536258094\n",
      "train loss:0.02874288125199326\n",
      "train loss:0.013664173436795917\n",
      "train loss:0.0462229359503775\n",
      "train loss:0.014707376348579762\n",
      "train loss:0.018500463680697455\n",
      "train loss:0.07163138410987796\n",
      "train loss:0.06661425890279468\n",
      "train loss:0.03365457162804533\n",
      "train loss:0.006808073472921907\n",
      "train loss:0.03535146323398853\n",
      "train loss:0.08371112708055004\n",
      "train loss:0.035933898599330105\n",
      "train loss:0.026795126375304408\n",
      "train loss:0.04520726862365209\n",
      "train loss:0.018057924421859814\n",
      "train loss:0.0445130016004622\n",
      "train loss:0.03272445273485584\n",
      "train loss:0.011599719616505124\n",
      "train loss:0.01054764142069863\n",
      "train loss:0.015667294001955653\n",
      "train loss:0.03085475786915984\n",
      "train loss:0.13077805546595075\n",
      "train loss:0.027486871098960513\n",
      "train loss:0.010893394123923704\n",
      "train loss:0.0411545033719247\n",
      "train loss:0.04734001753270755\n",
      "train loss:0.032015176564853025\n",
      "train loss:0.011028969444299413\n",
      "train loss:0.11890158634275505\n",
      "train loss:0.012779160966654551\n",
      "train loss:0.02433297678035892\n",
      "train loss:0.0620981167663146\n",
      "train loss:0.03495097858000544\n",
      "train loss:0.026045171722393342\n",
      "train loss:0.10809850296242868\n",
      "train loss:0.05088583893806871\n",
      "train loss:0.013661692245712294\n",
      "train loss:0.06271954003502538\n",
      "train loss:0.010544599381023279\n",
      "train loss:0.027978768068717897\n",
      "train loss:0.06725847846457855\n",
      "train loss:0.0072977783579195295\n",
      "train loss:0.019045111690140993\n",
      "train loss:0.07982085873422834\n",
      "train loss:0.03722453815490319\n",
      "train loss:0.01607343327600884\n",
      "train loss:0.014446402426280307\n",
      "train loss:0.01357696579262588\n",
      "train loss:0.01719553091518948\n",
      "train loss:0.05365848037841331\n",
      "train loss:0.03146940829839639\n",
      "train loss:0.06496742486172194\n",
      "train loss:0.020864819945142343\n",
      "train loss:0.03263507311428327\n",
      "train loss:0.01163775877052458\n",
      "train loss:0.023107697320501427\n",
      "train loss:0.044526828796820454\n",
      "train loss:0.008663602295194488\n",
      "train loss:0.004888507607994505\n",
      "train loss:0.055016080976693645\n",
      "train loss:0.0874489359780207\n",
      "train loss:0.010454661961386946\n",
      "train loss:0.029198079258380215\n",
      "train loss:0.015409752356870875\n",
      "train loss:0.05017854044318908\n",
      "train loss:0.04018022269528515\n",
      "train loss:0.05829468184220557\n",
      "train loss:0.08409853638450177\n",
      "train loss:0.015058000863107355\n",
      "train loss:0.024964270981816764\n",
      "train loss:0.035463321332622574\n",
      "train loss:0.0892008301214887\n",
      "train loss:0.02015089072029622\n",
      "train loss:0.02142061092165573\n",
      "train loss:0.03249176373368429\n",
      "train loss:0.023892407589722345\n",
      "train loss:0.01391205268069377\n",
      "train loss:0.011971664086844797\n",
      "train loss:0.035184118992220875\n",
      "train loss:0.13469100873710532\n",
      "train loss:0.04304868230322247\n",
      "train loss:0.01031642935353789\n",
      "train loss:0.06322094462137348\n",
      "train loss:0.003856607476653809\n",
      "train loss:0.008520127289857139\n",
      "train loss:0.033380400969919226\n",
      "train loss:0.014477620340248284\n",
      "train loss:0.01793570359278206\n",
      "train loss:0.08211519587688847\n",
      "train loss:0.034026673999839455\n",
      "train loss:0.029569215249423523\n",
      "train loss:0.006753317925954309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.022999739622310653\n",
      "train loss:0.06076317615873803\n",
      "train loss:0.0039356848000479385\n",
      "train loss:0.019516072118196073\n",
      "train loss:0.010203139820969898\n",
      "train loss:0.008013613118596259\n",
      "train loss:0.05968293803600223\n",
      "train loss:0.017230290821449962\n",
      "train loss:0.08974221404492201\n",
      "train loss:0.010160936581609737\n",
      "train loss:0.061816074676393454\n",
      "train loss:0.01798971728688618\n",
      "train loss:0.020462205630304632\n",
      "train loss:0.044007901655636186\n",
      "train loss:0.010085453048710096\n",
      "train loss:0.13301912743491548\n",
      "train loss:0.03819248915169521\n",
      "train loss:0.016050051859262577\n",
      "train loss:0.03997212632296078\n",
      "train loss:0.015812921991695192\n",
      "train loss:0.038416530519692446\n",
      "train loss:0.011790793257787528\n",
      "train loss:0.04608716686324168\n",
      "train loss:0.019543908331936706\n",
      "train loss:0.019256651712597807\n",
      "train loss:0.01032936081608558\n",
      "train loss:0.008809626282559628\n",
      "train loss:0.023335258393080868\n",
      "train loss:0.020322884047633504\n",
      "train loss:0.017785356686208224\n",
      "train loss:0.026147068836883117\n",
      "train loss:0.008517981453123899\n",
      "train loss:0.023638457538071308\n",
      "train loss:0.011622377166638515\n",
      "train loss:0.01826413577109101\n",
      "train loss:0.03739125594353196\n",
      "train loss:0.04059327837481821\n",
      "train loss:0.043289330734565715\n",
      "train loss:0.06929267662247511\n",
      "train loss:0.033571362128628546\n",
      "train loss:0.04496656208074693\n",
      "train loss:0.015541291481605511\n",
      "train loss:0.010220290872228375\n",
      "train loss:0.09003528850848909\n",
      "train loss:0.005673890018233767\n",
      "train loss:0.03975575518301494\n",
      "train loss:0.011025675898458494\n",
      "train loss:0.018127309904420748\n",
      "train loss:0.04501698640907998\n",
      "train loss:0.024016215898285394\n",
      "train loss:0.06730894835500481\n",
      "train loss:0.06688469537326497\n",
      "train loss:0.01891351935663125\n",
      "train loss:0.05156322717899106\n",
      "train loss:0.13094266826911038\n",
      "train loss:0.005878647486032935\n",
      "train loss:0.019775555794300837\n",
      "train loss:0.005378185733828642\n",
      "train loss:0.011033320077813723\n",
      "train loss:0.021891836537876724\n",
      "train loss:0.03638658267578363\n",
      "train loss:0.2468364497152724\n",
      "train loss:0.040183353536752266\n",
      "train loss:0.015063843184838482\n",
      "train loss:0.035154864825484945\n",
      "train loss:0.09093600784188627\n",
      "train loss:0.013943922985900421\n",
      "train loss:0.01868066780304021\n",
      "train loss:0.0227798631350359\n",
      "train loss:0.01936232183855633\n",
      "train loss:0.02225272097902905\n",
      "train loss:0.014469430259740729\n",
      "train loss:0.036940127458316915\n",
      "train loss:0.03904635886013507\n",
      "train loss:0.035618802387577635\n",
      "train loss:0.06954262103060314\n",
      "train loss:0.06875805095097123\n",
      "train loss:0.02869890330092374\n",
      "train loss:0.04664302552593376\n",
      "train loss:0.024286869492297525\n",
      "train loss:0.005567497459129425\n",
      "train loss:0.05451860063881085\n",
      "train loss:0.06067031088257005\n",
      "train loss:0.01969747464761258\n",
      "train loss:0.00832341248209869\n",
      "train loss:0.014435364971471987\n",
      "train loss:0.0171808643449036\n",
      "train loss:0.02818978495090193\n",
      "train loss:0.04080155910836763\n",
      "train loss:0.01763189027041582\n",
      "train loss:0.011274540257785825\n",
      "train loss:0.01751761841992413\n",
      "train loss:0.0784618896114172\n",
      "train loss:0.023327363191755518\n",
      "train loss:0.024105191013109928\n",
      "train loss:0.05160159233546979\n",
      "train loss:0.03395762364055168\n",
      "train loss:0.037181545799249614\n",
      "train loss:0.019493157017939\n",
      "train loss:0.01847256406527248\n",
      "train loss:0.019348923975873122\n",
      "train loss:0.019824084907256515\n",
      "train loss:0.10455129470989061\n",
      "train loss:0.07092444695000527\n",
      "train loss:0.017403732618380054\n",
      "train loss:0.051676302883316726\n",
      "train loss:0.028619179587073183\n",
      "train loss:0.016582937694074214\n",
      "train loss:0.1334649814811354\n",
      "train loss:0.08854201783630607\n",
      "train loss:0.013824445215494849\n",
      "train loss:0.01751002588352309\n",
      "train loss:0.04247050186734195\n",
      "train loss:0.19798324264504497\n",
      "train loss:0.012960253349613322\n",
      "train loss:0.010842415188622003\n",
      "train loss:0.011327259063388807\n",
      "train loss:0.02025768114226696\n",
      "train loss:0.006351401723436889\n",
      "train loss:0.024123103178696398\n",
      "train loss:0.023986784150849053\n",
      "train loss:0.024347429092010833\n",
      "train loss:0.01594946283792066\n",
      "train loss:0.056265391998887616\n",
      "train loss:0.05261462000791366\n",
      "train loss:0.025265002251944613\n",
      "train loss:0.03446046541000704\n",
      "train loss:0.08645788109318335\n",
      "train loss:0.015636547684442895\n",
      "train loss:0.015281499194598432\n",
      "train loss:0.021221531567921014\n",
      "train loss:0.04311962648987799\n",
      "train loss:0.030591240729811876\n",
      "train loss:0.04459278580567052\n",
      "train loss:0.029721140853187597\n",
      "train loss:0.009390592969382884\n",
      "train loss:0.015331615152310872\n",
      "train loss:0.014828534781469765\n",
      "train loss:0.053177504870306\n",
      "train loss:0.041197107799129266\n",
      "train loss:0.02365697373753203\n",
      "train loss:0.025617087210285484\n",
      "train loss:0.012678205721226774\n",
      "train loss:0.02702232762967549\n",
      "train loss:0.06670589904210987\n",
      "train loss:0.02243987074145788\n",
      "train loss:0.07327657243964732\n",
      "train loss:0.03488672309975605\n",
      "train loss:0.0053153643983084205\n",
      "train loss:0.016556920612021978\n",
      "train loss:0.012244144636959765\n",
      "train loss:0.022863097486529958\n",
      "train loss:0.10611794588518916\n",
      "train loss:0.0667188296597452\n",
      "train loss:0.0126579176760614\n",
      "train loss:0.01946909674158505\n",
      "train loss:0.048111557992903745\n",
      "train loss:0.019311342022859262\n",
      "train loss:0.010394118048552297\n",
      "train loss:0.01906057129551872\n",
      "train loss:0.02713766622225741\n",
      "train loss:0.011938887517841496\n",
      "train loss:0.029374770338817253\n",
      "train loss:0.044087558082045446\n",
      "train loss:0.00884913549403012\n",
      "train loss:0.007250670074119575\n",
      "train loss:0.055200319725032206\n",
      "train loss:0.04044178520177165\n",
      "train loss:0.04068827534922929\n",
      "train loss:0.006268511106113797\n",
      "train loss:0.01967728050514971\n",
      "train loss:0.041575549814284615\n",
      "train loss:0.031893317049692026\n",
      "train loss:0.06392579085744082\n",
      "train loss:0.084500999583228\n",
      "train loss:0.013005512278465952\n",
      "train loss:0.02457025085341499\n",
      "train loss:0.016697588585858836\n",
      "train loss:0.010145291303548836\n",
      "train loss:0.035819165003947544\n",
      "train loss:0.010287770303249606\n",
      "train loss:0.02017906709206187\n",
      "train loss:0.043569728807300215\n",
      "train loss:0.02364831035307297\n",
      "train loss:0.004935635082526732\n",
      "train loss:0.030675467437543232\n",
      "train loss:0.007869578480235452\n",
      "train loss:0.02465790801230868\n",
      "train loss:0.011358583912075384\n",
      "train loss:0.014829578265076833\n",
      "train loss:0.0895736062952666\n",
      "train loss:0.034958125737686\n",
      "train loss:0.015681663358171297\n",
      "train loss:0.02540552587601959\n",
      "train loss:0.024469608257985328\n",
      "train loss:0.0090445112654534\n",
      "train loss:0.012361684916999731\n",
      "train loss:0.009050561363564408\n",
      "train loss:0.042030550743660425\n",
      "train loss:0.05187092552726517\n",
      "train loss:0.06677965753562212\n",
      "train loss:0.012018248556373292\n",
      "train loss:0.03792904088430364\n",
      "train loss:0.06896307997761075\n",
      "train loss:0.024642479014876248\n",
      "train loss:0.012852321746984845\n",
      "train loss:0.027864607809243314\n",
      "train loss:0.030138289071935265\n",
      "train loss:0.024019429637595804\n",
      "train loss:0.057677751259683066\n",
      "train loss:0.024597117924195964\n",
      "train loss:0.008528487973560872\n",
      "train loss:0.04045660136410663\n",
      "train loss:0.02066977006155382\n",
      "train loss:0.009195898353391064\n",
      "train loss:0.0157726704448752\n",
      "train loss:0.025368072012874433\n",
      "train loss:0.008763045437125081\n",
      "train loss:0.026515615309766552\n",
      "train loss:0.02835579872504395\n",
      "train loss:0.0601941079546842\n",
      "train loss:0.023761729879505363\n",
      "train loss:0.05876082873405407\n",
      "train loss:0.02735717513466131\n",
      "train loss:0.029539028223041674\n",
      "train loss:0.028456588117831663\n",
      "train loss:0.00796522358326373\n",
      "train loss:0.04156533223773619\n",
      "train loss:0.019757262459365897\n",
      "train loss:0.0660966653292867\n",
      "train loss:0.010842597709886515\n",
      "train loss:0.022553408338785597\n",
      "train loss:0.011237035598699737\n",
      "train loss:0.02221723747301731\n",
      "train loss:0.014286754553563341\n",
      "train loss:0.030343277403838374\n",
      "train loss:0.005270584687329153\n",
      "train loss:0.02405254227446584\n",
      "train loss:0.03403598481647441\n",
      "train loss:0.019587235395429593\n",
      "train loss:0.009519884068157963\n",
      "train loss:0.020744180279420505\n",
      "train loss:0.053442283046320406\n",
      "train loss:0.06520526528536472\n",
      "train loss:0.007367933585766661\n",
      "train loss:0.02154339510554312\n",
      "train loss:0.07095879355098617\n",
      "train loss:0.01242494394675076\n",
      "train loss:0.009737568152174395\n",
      "train loss:0.02345916698795765\n",
      "train loss:0.01454019819803118\n",
      "train loss:0.007468609295180201\n",
      "train loss:0.02231226448217731\n",
      "train loss:0.011295579937582501\n",
      "train loss:0.03374315559865533\n",
      "train loss:0.04041190912784829\n",
      "train loss:0.0032471454739089385\n",
      "train loss:0.032476676988320546\n",
      "train loss:0.01819233542019166\n",
      "train loss:0.026197055047095526\n",
      "train loss:0.02559346238182846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.05414231130537706\n",
      "train loss:0.01249589197182801\n",
      "train loss:0.017096664306322493\n",
      "train loss:0.01793108323231606\n",
      "train loss:0.08031004614001098\n",
      "train loss:0.011013534316110862\n",
      "train loss:0.03515800984801394\n",
      "train loss:0.019963709678444855\n",
      "train loss:0.014285397510265854\n",
      "train loss:0.017964477121568245\n",
      "train loss:0.00772283746961735\n",
      "train loss:0.008544879090442317\n",
      "train loss:0.019498985044102742\n",
      "train loss:0.024827485434181708\n",
      "train loss:0.017199250910491962\n",
      "train loss:0.03139417924352271\n",
      "train loss:0.045053109980808824\n",
      "train loss:0.008254747577170955\n",
      "train loss:0.027582469197861986\n",
      "train loss:0.017765531252404862\n",
      "train loss:0.03695637184912286\n",
      "train loss:0.020154086193267803\n",
      "train loss:0.050284904686457216\n",
      "train loss:0.034134483247556434\n",
      "train loss:0.005523366371878977\n",
      "train loss:0.03485100495972621\n",
      "train loss:0.020168394185386587\n",
      "train loss:0.019339233854252975\n",
      "train loss:0.01599795671104431\n",
      "train loss:0.09029325955929987\n",
      "train loss:0.011416015913705441\n",
      "=== epoch:5, train acc:0.986, test acc:0.985 ===\n",
      "train loss:0.027646112249986556\n",
      "train loss:0.03509956184917355\n",
      "train loss:0.005840975262103005\n",
      "train loss:0.025236219353980075\n",
      "train loss:0.02169298791123694\n",
      "train loss:0.016325791379201773\n",
      "train loss:0.02055686924089181\n",
      "train loss:0.02575188218336371\n",
      "train loss:0.015334538336151855\n",
      "train loss:0.020066966901541826\n",
      "train loss:0.020250326786002252\n",
      "train loss:0.03009182572777518\n",
      "train loss:0.020766406630076544\n",
      "train loss:0.025159616070350683\n",
      "train loss:0.011639894522322714\n",
      "train loss:0.08726839648862131\n",
      "train loss:0.006048394210039396\n",
      "train loss:0.06040681481049887\n",
      "train loss:0.0063654372650830526\n",
      "train loss:0.02512710579824982\n",
      "train loss:0.023096343036171793\n",
      "train loss:0.014078203614830798\n",
      "train loss:0.008911057365511095\n",
      "train loss:0.0252513628720862\n",
      "train loss:0.07110725589761768\n",
      "train loss:0.004282450944392339\n",
      "train loss:0.01966993941061316\n",
      "train loss:0.010093069319416786\n",
      "train loss:0.03246610633746325\n",
      "train loss:0.009333487739655645\n",
      "train loss:0.06367193473151839\n",
      "train loss:0.016886675100126716\n",
      "train loss:0.013498598483774143\n",
      "train loss:0.020387154666742083\n",
      "train loss:0.010969046241439202\n",
      "train loss:0.0324947348036476\n",
      "train loss:0.013713916882891284\n",
      "train loss:0.023191152015014496\n",
      "train loss:0.018134190580477702\n",
      "train loss:0.018159736832904495\n",
      "train loss:0.00981828174984004\n",
      "train loss:0.03157869440324682\n",
      "train loss:0.06143460733212151\n",
      "train loss:0.07941828096156359\n",
      "train loss:0.033024898294007475\n",
      "train loss:0.01920182924222516\n",
      "train loss:0.05403291867987264\n",
      "train loss:0.04563469391322264\n",
      "train loss:0.05798722581378412\n",
      "train loss:0.007073075921394083\n",
      "train loss:0.017274024108181366\n",
      "train loss:0.09193723696634319\n",
      "train loss:0.014375802026442064\n",
      "train loss:0.02503088005935009\n",
      "train loss:0.006994991688579587\n",
      "train loss:0.017125581785524268\n",
      "train loss:0.05628177538544258\n",
      "train loss:0.015482990044416223\n",
      "train loss:0.02103448249473791\n",
      "train loss:0.0855019969634424\n",
      "train loss:0.055044728554763694\n",
      "train loss:0.01449485604533722\n",
      "train loss:0.033517326298548325\n",
      "train loss:0.03734130886387036\n",
      "train loss:0.009180641084778025\n",
      "train loss:0.004967844475843503\n",
      "train loss:0.08024735706885769\n",
      "train loss:0.018609205486542133\n",
      "train loss:0.027294866412058454\n",
      "train loss:0.010020184644734122\n",
      "train loss:0.02592409923394372\n",
      "train loss:0.02877253343265074\n",
      "train loss:0.03015896249300749\n",
      "train loss:0.020945948502340505\n",
      "train loss:0.017972919023688506\n",
      "train loss:0.012307703857757243\n",
      "train loss:0.015370134602548323\n",
      "train loss:0.0646487125128362\n",
      "train loss:0.003514808710248267\n",
      "train loss:0.041611097528365094\n",
      "train loss:0.011833015899365801\n",
      "train loss:0.018806269144845608\n",
      "train loss:0.02941804830973324\n",
      "train loss:0.0181385242953913\n",
      "train loss:0.06703903809412058\n",
      "train loss:0.024474772332273926\n",
      "train loss:0.017412914955453024\n",
      "train loss:0.006941844583665837\n",
      "train loss:0.033615963999707954\n",
      "train loss:0.031941162334331266\n",
      "train loss:0.0281253895062483\n",
      "train loss:0.02741771057899511\n",
      "train loss:0.01117701930773431\n",
      "train loss:0.026189127035983487\n",
      "train loss:0.020735572865690596\n",
      "train loss:0.05720820679681538\n",
      "train loss:0.035720586339432106\n",
      "train loss:0.006798593733095234\n",
      "train loss:0.09238951313498134\n",
      "train loss:0.033978594258019745\n",
      "train loss:0.019779938874692978\n",
      "train loss:0.010295304933285808\n",
      "train loss:0.002059364264785641\n",
      "train loss:0.011375144613957942\n",
      "train loss:0.02627129884648138\n",
      "train loss:0.06957826503515958\n",
      "train loss:0.06997808640286536\n",
      "train loss:0.036226959752320126\n",
      "train loss:0.03616315594433563\n",
      "train loss:0.01162747828208821\n",
      "train loss:0.004234811687833912\n",
      "train loss:0.015162542103264285\n",
      "train loss:0.0293898096426824\n",
      "train loss:0.008182650447870844\n",
      "train loss:0.008709482461264049\n",
      "train loss:0.06247926494135151\n",
      "train loss:0.013497317300328007\n",
      "train loss:0.03223007412147688\n",
      "train loss:0.07122212018567467\n",
      "train loss:0.01696246122758345\n",
      "train loss:0.025094131542512183\n",
      "train loss:0.006928586731207727\n",
      "train loss:0.01251962552173668\n",
      "train loss:0.024830936538227082\n",
      "train loss:0.005871792921237786\n",
      "train loss:0.01385063665503028\n",
      "train loss:0.016841496445910247\n",
      "train loss:0.006910752580638442\n",
      "train loss:0.01942966767828384\n",
      "train loss:0.07199322256263095\n",
      "train loss:0.05162806217417601\n",
      "train loss:0.04951213316347881\n",
      "train loss:0.011745071348954458\n",
      "train loss:0.03255094815530632\n",
      "train loss:0.027053472936556165\n",
      "train loss:0.03100277233026663\n",
      "train loss:0.013905702389045317\n",
      "train loss:0.02260247459315429\n",
      "train loss:0.009436289494824272\n",
      "train loss:0.007094513530696272\n",
      "train loss:0.026021631597723766\n",
      "train loss:0.016095971602750548\n",
      "train loss:0.061138689309363024\n",
      "train loss:0.016356656204271822\n",
      "train loss:0.06359665726712206\n",
      "train loss:0.010442805179733165\n",
      "train loss:0.013629385006660857\n",
      "train loss:0.02616903246687677\n",
      "train loss:0.07823129373359725\n",
      "train loss:0.0029058972612804653\n",
      "train loss:0.007066922507854913\n",
      "train loss:0.06293881399781659\n",
      "train loss:0.006426279596784463\n",
      "train loss:0.03094389847733293\n",
      "train loss:0.011903705849221844\n",
      "train loss:0.049664720151631876\n",
      "train loss:0.06986958840001176\n",
      "train loss:0.004861658883041996\n",
      "train loss:0.015134615837145099\n",
      "train loss:0.02797944365560079\n",
      "train loss:0.01864902258160433\n",
      "train loss:0.009859221411855353\n",
      "train loss:0.036237989651542096\n",
      "train loss:0.03158302019176052\n",
      "train loss:0.06111633213893003\n",
      "train loss:0.08770582404700569\n",
      "train loss:0.01360549159124473\n",
      "train loss:0.005116189006324146\n",
      "train loss:0.05021887600624766\n",
      "train loss:0.005734455304216578\n",
      "train loss:0.026573736339258292\n",
      "train loss:0.01985248502944654\n",
      "train loss:0.061758126593646795\n",
      "train loss:0.05524734731450101\n",
      "train loss:0.030268783689124463\n",
      "train loss:0.008680100037152727\n",
      "train loss:0.044278879057287626\n",
      "train loss:0.018578743056096282\n",
      "train loss:0.013363270925897517\n",
      "train loss:0.019526545211385388\n",
      "train loss:0.01913160144365383\n",
      "train loss:0.01670708555044094\n",
      "train loss:0.035434875137348096\n",
      "train loss:0.011926635019605432\n",
      "train loss:0.04127362694928442\n",
      "train loss:0.01693950232409537\n",
      "train loss:0.006029063293024311\n",
      "train loss:0.02317427563986422\n",
      "train loss:0.03595308448872415\n",
      "train loss:0.016276580866608773\n",
      "train loss:0.021733730924506815\n",
      "train loss:0.03489910583521476\n",
      "train loss:0.028536647650722047\n",
      "train loss:0.04079197272830044\n",
      "train loss:0.021317209569268226\n",
      "train loss:0.021255548989316916\n",
      "train loss:0.0466164882446121\n",
      "train loss:0.05159401691003935\n",
      "train loss:0.02283658015291881\n",
      "train loss:0.004163549328539276\n",
      "train loss:0.0215056888919431\n",
      "train loss:0.007031660725754595\n",
      "train loss:0.013928976710199048\n",
      "train loss:0.032269246564792395\n",
      "train loss:0.03997168849250693\n",
      "train loss:0.030863601608537676\n",
      "train loss:0.007894780472745883\n",
      "train loss:0.009457170438122902\n",
      "train loss:0.019000455546584426\n",
      "train loss:0.014240207243390077\n",
      "train loss:0.012084770380193312\n",
      "train loss:0.05009651617410189\n",
      "train loss:0.009141892009308707\n",
      "train loss:0.00550197704569099\n",
      "train loss:0.005413234690811417\n",
      "train loss:0.006779368223863668\n",
      "train loss:0.1925302434240127\n",
      "train loss:0.015099045569628917\n",
      "train loss:0.01646422425009276\n",
      "train loss:0.01794300813601115\n",
      "train loss:0.018946905136318214\n",
      "train loss:0.014548113747964634\n",
      "train loss:0.009004752580242031\n",
      "train loss:0.004422720146744667\n",
      "train loss:0.01074056410393352\n",
      "train loss:0.009364220187901557\n",
      "train loss:0.003408391413121199\n",
      "train loss:0.011983414794851764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.02910014691655119\n",
      "train loss:0.005514726740604391\n",
      "train loss:0.04616830876105535\n",
      "train loss:0.005689303806827464\n",
      "train loss:0.009774159668592533\n",
      "train loss:0.033504137196237675\n",
      "train loss:0.00766973453200045\n",
      "train loss:0.011318756471755526\n",
      "train loss:0.025948315305641106\n",
      "train loss:0.009356765030035744\n",
      "train loss:0.014279749387180603\n",
      "train loss:0.04399678636662104\n",
      "train loss:0.018362120061438\n",
      "train loss:0.0663211553464844\n",
      "train loss:0.04736951398282538\n",
      "train loss:0.020445287463448442\n",
      "train loss:0.007256131942496281\n",
      "train loss:0.01680193400018863\n",
      "train loss:0.0018176807205171437\n",
      "train loss:0.04309877241913232\n",
      "train loss:0.009019280174291648\n",
      "train loss:0.043019620165707435\n",
      "train loss:0.01677117215804217\n",
      "train loss:0.012161044588274592\n",
      "train loss:0.06030945558209624\n",
      "train loss:0.0778774080760842\n",
      "train loss:0.060067499783148175\n",
      "train loss:0.020833842443520805\n",
      "train loss:0.10911492543223918\n",
      "train loss:0.05541742673102708\n",
      "train loss:0.0032817662584603484\n",
      "train loss:0.01367391063762986\n",
      "train loss:0.04841668535349619\n",
      "train loss:0.0897321395991654\n",
      "train loss:0.02465742647671731\n",
      "train loss:0.022415968225719562\n",
      "train loss:0.00477098304650997\n",
      "train loss:0.027321603349600584\n",
      "train loss:0.010448114837653233\n",
      "train loss:0.02063913344085761\n",
      "train loss:0.010441372991068903\n",
      "train loss:0.020772755079388968\n",
      "train loss:0.008105988175816856\n",
      "train loss:0.03727664930377128\n",
      "train loss:0.01883434280075984\n",
      "train loss:0.017257999455305064\n",
      "train loss:0.03247287831408091\n",
      "train loss:0.028903968955489082\n",
      "train loss:0.049453085256897344\n",
      "train loss:0.014393432320228865\n",
      "train loss:0.029559332430495217\n",
      "train loss:0.030765599828611257\n",
      "train loss:0.021959523405128696\n",
      "train loss:0.007007735284985974\n",
      "train loss:0.014487250140572823\n",
      "train loss:0.0463716976573395\n",
      "train loss:0.010304722071146591\n",
      "train loss:0.004024661425844541\n",
      "train loss:0.010656418653192173\n",
      "train loss:0.014885222403824814\n",
      "train loss:0.02388013977564521\n",
      "train loss:0.01279425667159812\n",
      "train loss:0.03588623973389949\n",
      "train loss:0.023210428938771663\n",
      "train loss:0.0052514146227296546\n",
      "train loss:0.03548980208182001\n",
      "train loss:0.05722400193648682\n",
      "train loss:0.02899470513691699\n",
      "train loss:0.018934490089627217\n",
      "train loss:0.017560429840835442\n",
      "train loss:0.010732709734115206\n",
      "train loss:0.008490648380743794\n",
      "train loss:0.024345730178107528\n",
      "train loss:0.018763582160435742\n",
      "train loss:0.007080789775260107\n",
      "train loss:0.016749861821317377\n",
      "train loss:0.05826541026290297\n",
      "train loss:0.015766149889389083\n",
      "train loss:0.006654588811586652\n",
      "train loss:0.006593097816349424\n",
      "train loss:0.014934002349000884\n",
      "train loss:0.026185945007158033\n",
      "train loss:0.006370145264757388\n",
      "train loss:0.0106922599893778\n",
      "train loss:0.02729958309918281\n",
      "train loss:0.01953101395766635\n",
      "train loss:0.006333189166599772\n",
      "train loss:0.029014269932514013\n",
      "train loss:0.026362293665603484\n",
      "train loss:0.014411044159602291\n",
      "train loss:0.04033809662512058\n",
      "train loss:0.024818172738468456\n",
      "train loss:0.016047951550855328\n",
      "train loss:0.056374275940621915\n",
      "train loss:0.03593234285933479\n",
      "train loss:0.028996013356795743\n",
      "train loss:0.019928886987549275\n",
      "train loss:0.031169510329312727\n",
      "train loss:0.1356851002768912\n",
      "train loss:0.05663593304926794\n",
      "train loss:0.016141358140673356\n",
      "train loss:0.020458439752951932\n",
      "train loss:0.06065514585411101\n",
      "train loss:0.01626392944141007\n",
      "train loss:0.016500987909760668\n",
      "train loss:0.021080388924951645\n",
      "train loss:0.040756080643812344\n",
      "train loss:0.013794637159653072\n",
      "train loss:0.026403408575863922\n",
      "train loss:0.008171568596782166\n",
      "train loss:0.021101481464216202\n",
      "train loss:0.020293639444056103\n",
      "train loss:0.016226417215325563\n",
      "train loss:0.02645361082596425\n",
      "train loss:0.0034005368323572287\n",
      "train loss:0.015612008708580314\n",
      "train loss:0.020723439232181815\n",
      "train loss:0.0031258659494299555\n",
      "train loss:0.05190916907653405\n",
      "train loss:0.011365638895637697\n",
      "train loss:0.014294172396694525\n",
      "train loss:0.031152736704825535\n",
      "train loss:0.011053903067705621\n",
      "train loss:0.01149904953741601\n",
      "train loss:0.01067501328037011\n",
      "train loss:0.04947325690902902\n",
      "train loss:0.03823058205153859\n",
      "train loss:0.0315616037070472\n",
      "train loss:0.060364992429704396\n",
      "train loss:0.01102298511322479\n",
      "train loss:0.02067818821409972\n",
      "train loss:0.027264955387661396\n",
      "train loss:0.010131732128968382\n",
      "train loss:0.010353323206157592\n",
      "train loss:0.010392404451302722\n",
      "train loss:0.01571546926871104\n",
      "train loss:0.011529479665796765\n",
      "train loss:0.010084667089889525\n",
      "train loss:0.0430442684685779\n",
      "train loss:0.019244860334553054\n",
      "train loss:0.06160274337799934\n",
      "train loss:0.015560097711483818\n",
      "train loss:0.012351398703122907\n",
      "train loss:0.017997572799182664\n",
      "train loss:0.0627649467249443\n",
      "train loss:0.016482636801094807\n",
      "train loss:0.014015284027463399\n",
      "train loss:0.0057476709334504114\n",
      "train loss:0.021271455293404084\n",
      "train loss:0.01811754551401807\n",
      "train loss:0.05709970942818256\n",
      "train loss:0.010221175711929615\n",
      "train loss:0.022692134762269216\n",
      "train loss:0.040829790147426964\n",
      "train loss:0.019093588053815978\n",
      "train loss:0.006073378297637668\n",
      "train loss:0.02299778072565374\n",
      "train loss:0.04678023283908526\n",
      "train loss:0.014060959067042592\n",
      "train loss:0.0034981093371918744\n",
      "train loss:0.005740793615608379\n",
      "train loss:0.02079528761359021\n",
      "train loss:0.025666808046238988\n",
      "train loss:0.015836313011592648\n",
      "train loss:0.03575202283916983\n",
      "train loss:0.04876834726655353\n",
      "train loss:0.02255134421257259\n",
      "train loss:0.02862340384870871\n",
      "train loss:0.010666683688345835\n",
      "train loss:0.007357910184496066\n",
      "train loss:0.00945431218656725\n",
      "train loss:0.012997696082845797\n",
      "train loss:0.011752857693472887\n",
      "train loss:0.013286572255136265\n",
      "train loss:0.02155952323381102\n",
      "train loss:0.009735499886211358\n",
      "train loss:0.027982162685077316\n",
      "train loss:0.009748479726897005\n",
      "train loss:0.030818998478135372\n",
      "train loss:0.010231895576789026\n",
      "train loss:0.02576996393008153\n",
      "train loss:0.04286182340184288\n",
      "train loss:0.004290215971278493\n",
      "train loss:0.022158045002852757\n",
      "train loss:0.006723147611812233\n",
      "train loss:0.018380606696119895\n",
      "train loss:0.023619734908551956\n",
      "train loss:0.013298396158045424\n",
      "train loss:0.005318866164577675\n",
      "train loss:0.008799298900187274\n",
      "train loss:0.05244610962565024\n",
      "train loss:0.0474539715872498\n",
      "train loss:0.014974988885507981\n",
      "train loss:0.019317368939442806\n",
      "train loss:0.005551167406605383\n",
      "train loss:0.07243590893924144\n",
      "train loss:0.024997268884550027\n",
      "train loss:0.007099366684010193\n",
      "train loss:0.07821542771745332\n",
      "train loss:0.028293880287119353\n",
      "train loss:0.056001707640720204\n",
      "train loss:0.0022460301724682493\n",
      "train loss:0.01516018201188072\n",
      "train loss:0.041725863594267894\n",
      "train loss:0.060709918537285995\n",
      "train loss:0.01879621903775005\n",
      "train loss:0.015153055484976667\n",
      "train loss:0.022827009945678295\n",
      "train loss:0.01218515860664854\n",
      "train loss:0.01211874252620746\n",
      "train loss:0.014391079419325293\n",
      "train loss:0.053426829708762495\n",
      "train loss:0.025142130784024445\n",
      "train loss:0.02584953424158011\n",
      "train loss:0.03072361468554628\n",
      "train loss:0.009572308781735267\n",
      "train loss:0.004702031984553585\n",
      "train loss:0.11996333616475013\n",
      "train loss:0.04162715780190737\n",
      "train loss:0.022683764859586543\n",
      "train loss:0.007871526913569732\n",
      "train loss:0.013168409454390404\n",
      "train loss:0.009378033449354511\n",
      "train loss:0.011673633575451332\n",
      "train loss:0.006244023004517811\n",
      "train loss:0.02114860455796165\n",
      "train loss:0.04233409252695423\n",
      "train loss:0.038396670318004436\n",
      "train loss:0.004269149451882707\n",
      "train loss:0.04403114851546277\n",
      "train loss:0.06370210667141808\n",
      "train loss:0.01323639653510585\n",
      "train loss:0.050528255439451136\n",
      "train loss:0.006935201457927042\n",
      "train loss:0.035484418089421016\n",
      "train loss:0.022311697139531766\n",
      "train loss:0.03136464144086709\n",
      "train loss:0.013564165839000813\n",
      "train loss:0.03955119189909282\n",
      "train loss:0.03845438868460385\n",
      "train loss:0.008316820544101327\n",
      "train loss:0.007753585332139576\n",
      "train loss:0.023367625149178686\n",
      "train loss:0.01075122032281203\n",
      "train loss:0.011195705137755314\n",
      "train loss:0.022318743450014913\n",
      "train loss:0.018378751873220814\n",
      "train loss:0.009709145910986539\n",
      "train loss:0.03432173813375866\n",
      "train loss:0.032569103988800197\n",
      "train loss:0.005103956791616334\n",
      "train loss:0.02093023750133365\n",
      "train loss:0.00771773246438115\n",
      "train loss:0.021842908159777852\n",
      "train loss:0.08534591515448907\n",
      "train loss:0.009490058133260225\n",
      "train loss:0.06239181933386487\n",
      "train loss:0.01776415027602146\n",
      "train loss:0.027192011776013384\n",
      "train loss:0.00907075153354452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.08556636247897335\n",
      "train loss:0.018635430101108897\n",
      "train loss:0.03008896344894154\n",
      "train loss:0.013510848933813893\n",
      "train loss:0.04774569922768745\n",
      "train loss:0.04145450893432094\n",
      "train loss:0.019111070508587617\n",
      "train loss:0.01414765427989361\n",
      "train loss:0.002183690260794272\n",
      "train loss:0.015031787688569165\n",
      "train loss:0.01978382671471862\n",
      "train loss:0.06328709438632249\n",
      "train loss:0.028056732996433333\n",
      "train loss:0.016688576176479494\n",
      "train loss:0.0378869276944854\n",
      "train loss:0.048868719783676545\n",
      "train loss:0.004080581472277002\n",
      "train loss:0.009423403282613823\n",
      "train loss:0.006637793064267066\n",
      "train loss:0.023429107215127854\n",
      "train loss:0.006416700443572536\n",
      "train loss:0.06190038358582313\n",
      "train loss:0.011546914079822787\n",
      "train loss:0.039876649902949195\n",
      "train loss:0.0016189329798539636\n",
      "train loss:0.06802048982006198\n",
      "train loss:0.016274057047310907\n",
      "train loss:0.029733529933712245\n",
      "train loss:0.08369408869629061\n",
      "train loss:0.029774234328434415\n",
      "train loss:0.0028683523684530808\n",
      "train loss:0.03835848476317543\n",
      "train loss:0.0069049302112727485\n",
      "train loss:0.011453127705437494\n",
      "train loss:0.043462943264139214\n",
      "train loss:0.018361320914668078\n",
      "train loss:0.0089584532577775\n",
      "train loss:0.03015501221620384\n",
      "train loss:0.011375372161561974\n",
      "train loss:0.008354913897167202\n",
      "train loss:0.010747407968136058\n",
      "train loss:0.027592980355074962\n",
      "train loss:0.011338727023578608\n",
      "train loss:0.02068485155088154\n",
      "train loss:0.019129613197681538\n",
      "train loss:0.02090168050521371\n",
      "train loss:0.02897224752899181\n",
      "train loss:0.01880947169576582\n",
      "train loss:0.04094097139123875\n",
      "train loss:0.015288102024259547\n",
      "train loss:0.012237973960019482\n",
      "train loss:0.02673726313287343\n",
      "train loss:0.004718120670577172\n",
      "train loss:0.01136766724495109\n",
      "train loss:0.019062248593843475\n",
      "train loss:0.021400717509498346\n",
      "train loss:0.012399626352936989\n",
      "train loss:0.012791303740787354\n",
      "train loss:0.008760355008711423\n",
      "train loss:0.005275823657403565\n",
      "train loss:0.01135008037260702\n",
      "train loss:0.004950358241301666\n",
      "train loss:0.0033731520277262205\n",
      "train loss:0.009867600461438409\n",
      "train loss:0.078224179639342\n",
      "train loss:0.024754507701348082\n",
      "train loss:0.01453843437607091\n",
      "train loss:0.015692150089551243\n",
      "train loss:0.06344601621523445\n",
      "train loss:0.03135703624993281\n",
      "train loss:0.013860680335893412\n",
      "train loss:0.01896914165755791\n",
      "train loss:0.014868718918542023\n",
      "train loss:0.04937733058708234\n",
      "train loss:0.02472687386203508\n",
      "train loss:0.012042659477327864\n",
      "train loss:0.003933607350301906\n",
      "train loss:0.07428870358400434\n",
      "train loss:0.006361934444023468\n",
      "train loss:0.008599047208596505\n",
      "train loss:0.0031317831147036294\n",
      "train loss:0.008720185326523789\n",
      "train loss:0.02889626126739163\n",
      "train loss:0.017599396604646735\n",
      "train loss:0.011208879454069414\n",
      "train loss:0.01025819449195388\n",
      "train loss:0.030356864353236923\n",
      "train loss:0.03905958847517988\n",
      "train loss:0.049440730733900616\n",
      "train loss:0.009298796538880398\n",
      "train loss:0.009809105544122265\n",
      "train loss:0.00948966345929749\n",
      "train loss:0.01744230758908423\n",
      "train loss:0.013575855201075465\n",
      "train loss:0.02020925488426296\n",
      "train loss:0.021680603249238907\n",
      "train loss:0.03854432452080418\n",
      "train loss:0.05690621847415586\n",
      "train loss:0.007169823899008055\n",
      "train loss:0.011860414629034118\n",
      "train loss:0.011720136603088767\n",
      "train loss:0.006617107326528169\n",
      "train loss:0.04309192618106504\n",
      "train loss:0.009481462929637339\n",
      "train loss:0.05209142702781461\n",
      "train loss:0.0342228044835122\n",
      "train loss:0.026728646944152317\n",
      "train loss:0.007191640940589812\n",
      "train loss:0.005992445136670181\n",
      "train loss:0.023649927892537205\n",
      "train loss:0.008889993613875437\n",
      "train loss:0.040327183193922506\n",
      "=== epoch:6, train acc:0.986, test acc:0.985 ===\n",
      "train loss:0.026850996629481615\n",
      "train loss:0.006226476188174866\n",
      "train loss:0.016458777019598112\n",
      "train loss:0.004234588804141861\n",
      "train loss:0.008837575299035748\n",
      "train loss:0.0033769745977168908\n",
      "train loss:0.02159600177269852\n",
      "train loss:0.008739442404444539\n",
      "train loss:0.009303067321639264\n",
      "train loss:0.005388887058518337\n",
      "train loss:0.007368402765260486\n",
      "train loss:0.01706911979122503\n",
      "train loss:0.005847288525419974\n",
      "train loss:0.003902046444287749\n",
      "train loss:0.0058101571186205\n",
      "train loss:0.11046703653815992\n",
      "train loss:0.006667401710657003\n",
      "train loss:0.014667216594470183\n",
      "train loss:0.03517757752024071\n",
      "train loss:0.009344741697764386\n",
      "train loss:0.02876997827322677\n",
      "train loss:0.0037422508427719737\n",
      "train loss:0.019731834371061883\n",
      "train loss:0.017427767984732254\n",
      "train loss:0.01723362434088682\n",
      "train loss:0.005974857590135445\n",
      "train loss:0.014802997893821621\n",
      "train loss:0.010475322540687625\n",
      "train loss:0.004694326273448558\n",
      "train loss:0.04405663662966197\n",
      "train loss:0.016709001328645386\n",
      "train loss:0.1504468150108121\n",
      "train loss:0.019963494381501416\n",
      "train loss:0.015163220508875473\n",
      "train loss:0.013750684745348676\n",
      "train loss:0.010201654760569778\n",
      "train loss:0.008814140041145847\n",
      "train loss:0.0557041078117202\n",
      "train loss:0.02483461157433343\n",
      "train loss:0.039098754420172334\n",
      "train loss:0.03589550825801256\n",
      "train loss:0.010718067575457133\n",
      "train loss:0.026663713021273076\n",
      "train loss:0.012997827525033218\n",
      "train loss:0.014205388624253497\n",
      "train loss:0.008823236591412166\n",
      "train loss:0.0024318079019598634\n",
      "train loss:0.00823556436227238\n",
      "train loss:0.010805791499675815\n",
      "train loss:0.019983305298675043\n",
      "train loss:0.005198177379116256\n",
      "train loss:0.020863997998670697\n",
      "train loss:0.007592117221545644\n",
      "train loss:0.01967142990665355\n",
      "train loss:0.011857677946424902\n",
      "train loss:0.013413067399394484\n",
      "train loss:0.013195428524408795\n",
      "train loss:0.039797226775923365\n",
      "train loss:0.0019005328791902327\n",
      "train loss:0.03348973331332587\n",
      "train loss:0.005323667877177126\n",
      "train loss:0.0210222439007222\n",
      "train loss:0.007055766345107439\n",
      "train loss:0.013055180147871555\n",
      "train loss:0.011543992608574506\n",
      "train loss:0.009636264924053223\n",
      "train loss:0.016168845283375505\n",
      "train loss:0.004261826345224821\n",
      "train loss:0.008114966913839628\n",
      "train loss:0.01296685442762906\n",
      "train loss:0.007328694478005871\n",
      "train loss:0.05081726378149805\n",
      "train loss:0.012421619410767793\n",
      "train loss:0.0031579041214826165\n",
      "train loss:0.008532697427553245\n",
      "train loss:0.03194553109456093\n",
      "train loss:0.026815491672559012\n",
      "train loss:0.006513110311966414\n",
      "train loss:0.01026154300221798\n",
      "train loss:0.008482667436746878\n",
      "train loss:0.0471961089971966\n",
      "train loss:0.05456803214396051\n",
      "train loss:0.06708458648301258\n",
      "train loss:0.0099047993971388\n",
      "train loss:0.023563780713732278\n",
      "train loss:0.02969271505199559\n",
      "train loss:0.008675203255104241\n",
      "train loss:0.019798263322341646\n",
      "train loss:0.007910945041676857\n",
      "train loss:0.010535214275134404\n",
      "train loss:0.03341510519577575\n",
      "train loss:0.0063592863560274415\n",
      "train loss:0.006859198513991173\n",
      "train loss:0.031792288497020454\n",
      "train loss:0.01509746615156652\n",
      "train loss:0.01680359416332543\n",
      "train loss:0.016870912437085543\n",
      "train loss:0.008472912133049968\n",
      "train loss:0.025884681563040104\n",
      "train loss:0.0017055979878147214\n",
      "train loss:0.013149712722709645\n",
      "train loss:0.012279068242736144\n",
      "train loss:0.019020622643056498\n",
      "train loss:0.05502681803459808\n",
      "train loss:0.007285538822909763\n",
      "train loss:0.12350487659196607\n",
      "train loss:0.029929294944676915\n",
      "train loss:0.011370851472853723\n",
      "train loss:0.01775610684664441\n",
      "train loss:0.0877874329932337\n",
      "train loss:0.048586064684285765\n",
      "train loss:0.019465107079803975\n",
      "train loss:0.0025308650170006363\n",
      "train loss:0.012944861655531876\n",
      "train loss:0.007569521275581688\n",
      "train loss:0.021496247470631925\n",
      "train loss:0.027590857706357233\n",
      "train loss:0.007950955025855314\n",
      "train loss:0.004450622752909566\n",
      "train loss:0.02625476452928607\n",
      "train loss:0.018824865326753176\n",
      "train loss:0.0066200898307796395\n",
      "train loss:0.033747455476777335\n",
      "train loss:0.02195689512492954\n",
      "train loss:0.023930385627215455\n",
      "train loss:0.005737693126444256\n",
      "train loss:0.012009137346204285\n",
      "train loss:0.0035809712610212385\n",
      "train loss:0.030719574788830358\n",
      "train loss:0.03677588267884938\n",
      "train loss:0.0555010447613386\n",
      "train loss:0.03130347701718261\n",
      "train loss:0.0184292635361528\n",
      "train loss:0.02898513467614547\n",
      "train loss:0.021208045174652815\n",
      "train loss:0.07728871861065574\n",
      "train loss:0.011143550872417356\n",
      "train loss:0.013752325976152032\n",
      "train loss:0.006613748407837754\n",
      "train loss:0.037783372978167924\n",
      "train loss:0.006357573285341894\n",
      "train loss:0.05714316756919399\n",
      "train loss:0.0252593272714246\n",
      "train loss:0.03227214808240689\n",
      "train loss:0.027100719726625998\n",
      "train loss:0.05938199471304191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.017079583053355794\n",
      "train loss:0.014898193872931252\n",
      "train loss:0.0512691301574971\n",
      "train loss:0.008693941113690788\n",
      "train loss:0.01989153431891963\n",
      "train loss:0.01675258730996443\n",
      "train loss:0.03823545975983906\n",
      "train loss:0.03914947879999285\n",
      "train loss:0.06878771509599745\n",
      "train loss:0.01391698582817475\n",
      "train loss:0.03266826247015679\n",
      "train loss:0.029186153381310503\n",
      "train loss:0.09314384144779517\n",
      "train loss:0.010104810741262984\n",
      "train loss:0.02389931654779515\n",
      "train loss:0.02332790976564568\n",
      "train loss:0.032722990315433964\n",
      "train loss:0.013311734839073412\n",
      "train loss:0.020623690123004926\n",
      "train loss:0.004665871224195735\n",
      "train loss:0.13544990323460954\n",
      "train loss:0.004004917031060705\n",
      "train loss:0.01305141073078902\n",
      "train loss:0.021440453035766086\n",
      "train loss:0.015590668582207033\n",
      "train loss:0.006156905189675963\n",
      "train loss:0.0038892371350265644\n",
      "train loss:0.11682392814823717\n",
      "train loss:0.08178923287178297\n",
      "train loss:0.007254808874313866\n",
      "train loss:0.02461074131006951\n",
      "train loss:0.019984451153026977\n",
      "train loss:0.001932603706117326\n",
      "train loss:0.09073379487054929\n",
      "train loss:0.006684491910706331\n",
      "train loss:0.00270093038865398\n",
      "train loss:0.003518688499326824\n",
      "train loss:0.008791106212687676\n",
      "train loss:0.016476090067704726\n",
      "train loss:0.017081740937708957\n",
      "train loss:0.012696159148087851\n",
      "train loss:0.03382247387938064\n",
      "train loss:0.020731955552264914\n",
      "train loss:0.06325715808621739\n",
      "train loss:0.02057190823622013\n",
      "train loss:0.0060118591700737585\n",
      "train loss:0.0225904028307685\n",
      "train loss:0.010075895179768193\n",
      "train loss:0.006682676297184959\n",
      "train loss:0.026977773668922723\n",
      "train loss:0.002671500408505995\n",
      "train loss:0.011339306784785185\n",
      "train loss:0.03964260099699382\n",
      "train loss:0.0617239396421917\n",
      "train loss:0.13825469345032984\n",
      "train loss:0.007035863169866858\n",
      "train loss:0.01230016789736994\n",
      "train loss:0.012009548134045282\n",
      "train loss:0.07804906128993504\n",
      "train loss:0.0098791417068819\n",
      "train loss:0.00936808176753658\n",
      "train loss:0.0047324810987995364\n",
      "train loss:0.02218314756170022\n",
      "train loss:0.033328696451590624\n",
      "train loss:0.03350655323279058\n",
      "train loss:0.03165886111446492\n",
      "train loss:0.008157328460815565\n",
      "train loss:0.015433063679748817\n",
      "train loss:0.022229586915676013\n",
      "train loss:0.009589236840531125\n",
      "train loss:0.006717029960725307\n",
      "train loss:0.022451640825690115\n",
      "train loss:0.012083607837693742\n",
      "train loss:0.013834173203250916\n",
      "train loss:0.020711666881087738\n",
      "train loss:0.0036643281485172737\n",
      "train loss:0.06105611841439394\n",
      "train loss:0.008956032709059434\n",
      "train loss:0.020085347677510305\n",
      "train loss:0.02994737131291143\n",
      "train loss:0.030531956705647824\n",
      "train loss:0.01198793888613542\n",
      "train loss:0.004447299710880512\n",
      "train loss:0.011842008256876679\n",
      "train loss:0.010342723761856777\n",
      "train loss:0.006169975602853107\n",
      "train loss:0.06125731831393388\n",
      "train loss:0.0245886683640535\n",
      "train loss:0.004478262857582671\n",
      "train loss:0.04904718893110812\n",
      "train loss:0.017733909286897977\n",
      "train loss:0.031236226365979985\n",
      "train loss:0.015059701654719877\n",
      "train loss:0.02038395273650234\n",
      "train loss:0.003949753273373282\n",
      "train loss:0.008881973412552894\n",
      "train loss:0.011401500120880911\n",
      "train loss:0.009800644752807135\n",
      "train loss:0.004003983270114154\n",
      "train loss:0.006893553839452241\n",
      "train loss:0.009219461773158528\n",
      "train loss:0.01735684021235058\n",
      "train loss:0.03474771855844604\n",
      "train loss:0.0045325474260155705\n",
      "train loss:0.016966574791233847\n",
      "train loss:0.005383729773009386\n",
      "train loss:0.0415056568630222\n",
      "train loss:0.01715523388000223\n",
      "train loss:0.03726522208334344\n",
      "train loss:0.003935779323192295\n",
      "train loss:0.006418939604336924\n",
      "train loss:0.010710708068724692\n",
      "train loss:0.011265519653656653\n",
      "train loss:0.009241041412226137\n",
      "train loss:0.01538673513827612\n",
      "train loss:0.02057717082395449\n",
      "train loss:0.0042883216033193046\n",
      "train loss:0.010427222436306331\n",
      "train loss:0.007500486487224067\n",
      "train loss:0.028026038212233168\n",
      "train loss:0.021922034750619383\n",
      "train loss:0.01351620705531258\n",
      "train loss:0.005454503861309249\n",
      "train loss:0.05343727030361385\n",
      "train loss:0.006167299760771577\n",
      "train loss:0.026131057577961\n",
      "train loss:0.017094604824603756\n",
      "train loss:0.014516140388708167\n",
      "train loss:0.07298652969891763\n",
      "train loss:0.05962961662423037\n",
      "train loss:0.004793108423065086\n",
      "train loss:0.012039449754876317\n",
      "train loss:0.01662165606036736\n",
      "train loss:0.013134277592858276\n",
      "train loss:0.006136700515452002\n",
      "train loss:0.07738866003358007\n",
      "train loss:0.009166506830389002\n",
      "train loss:0.006627794013630953\n",
      "train loss:0.014112175791732079\n",
      "train loss:0.025041127307969983\n",
      "train loss:0.00875493364595258\n",
      "train loss:0.008404550695753896\n",
      "train loss:0.0357426911259647\n",
      "train loss:0.07662862180269756\n",
      "train loss:0.04035060054699662\n",
      "train loss:0.012976091785276504\n",
      "train loss:0.011358566242318466\n",
      "train loss:0.014320871709404126\n",
      "train loss:0.016280035125834542\n",
      "train loss:0.006303699617857344\n",
      "train loss:0.008224523434681792\n",
      "train loss:0.015616885706400054\n",
      "train loss:0.025781747622939125\n",
      "train loss:0.012053550449015174\n",
      "train loss:0.04576812237741108\n",
      "train loss:0.014363091766483729\n",
      "train loss:0.02632578471249152\n",
      "train loss:0.015072347509798877\n",
      "train loss:0.03755936360224596\n",
      "train loss:0.05182349921624699\n",
      "train loss:0.019023118817087247\n",
      "train loss:0.04923029095620292\n",
      "train loss:0.012329429686451298\n",
      "train loss:0.033201362797573145\n",
      "train loss:0.007099061351084778\n",
      "train loss:0.031513091875868524\n",
      "train loss:0.0478933337934721\n",
      "train loss:0.024092522360435447\n",
      "train loss:0.012630668163697628\n",
      "train loss:0.02064607918583035\n",
      "train loss:0.004138130419716697\n",
      "train loss:0.014681780370724122\n",
      "train loss:0.06311902869034569\n",
      "train loss:0.008232189794160434\n",
      "train loss:0.022901015283253792\n",
      "train loss:0.2440199259514555\n",
      "train loss:0.01622210267638557\n",
      "train loss:0.012660818824402807\n",
      "train loss:0.030714808690470198\n",
      "train loss:0.022611944653030756\n",
      "train loss:0.0031946171040791948\n",
      "train loss:0.006357646034971311\n",
      "train loss:0.022890251004320298\n",
      "train loss:0.012576280629655583\n",
      "train loss:0.004080770429616509\n",
      "train loss:0.009938045801254413\n",
      "train loss:0.02792516201525541\n",
      "train loss:0.04234462756728643\n",
      "train loss:0.017665910760899396\n",
      "train loss:0.12173361986981915\n",
      "train loss:0.028194707050440262\n",
      "train loss:0.07348017424961531\n",
      "train loss:0.046952044546351226\n",
      "train loss:0.003874661324334598\n",
      "train loss:0.026639664667350186\n",
      "train loss:0.01120904036445699\n",
      "train loss:0.027333953913746684\n",
      "train loss:0.019602921050255278\n",
      "train loss:0.00792723967995575\n",
      "train loss:0.028075004344641396\n",
      "train loss:0.01002336402550948\n",
      "train loss:0.027864196689911472\n",
      "train loss:0.0024925677357317115\n",
      "train loss:0.007620239644061913\n",
      "train loss:0.004225594397110743\n",
      "train loss:0.023984051955849503\n",
      "train loss:0.018822059189812182\n",
      "train loss:0.00560542953349326\n",
      "train loss:0.002212673081295608\n",
      "train loss:0.016551472733087703\n",
      "train loss:0.03563900597224705\n",
      "train loss:0.011044004833914736\n",
      "train loss:0.012668767923619534\n",
      "train loss:0.02102930361707593\n",
      "train loss:0.02766094974462003\n",
      "train loss:0.026989489962212742\n",
      "train loss:0.007308181504461683\n",
      "train loss:0.0029644824471463287\n",
      "train loss:0.008148348318407021\n",
      "train loss:0.008928047454718249\n",
      "train loss:0.011811060579011205\n",
      "train loss:0.012052999584436482\n",
      "train loss:0.0036669638076863554\n",
      "train loss:0.0701320396072008\n",
      "train loss:0.009052600860551936\n",
      "train loss:0.00307480053320806\n",
      "train loss:0.011995882238519327\n",
      "train loss:0.012096989254946516\n",
      "train loss:0.019501879370595766\n",
      "train loss:0.009655021227113121\n",
      "train loss:0.006058752098319615\n",
      "train loss:0.04187051836009035\n",
      "train loss:0.018719510530601117\n",
      "train loss:0.012422356992367106\n",
      "train loss:0.0059725258260984295\n",
      "train loss:0.00951564118867066\n",
      "train loss:0.010183120692560001\n",
      "train loss:0.0052774947416545015\n",
      "train loss:0.022373476431464\n",
      "train loss:0.006686117197763181\n",
      "train loss:0.008051921393936536\n",
      "train loss:0.01912121800065799\n",
      "train loss:0.011023911365856896\n",
      "train loss:0.05719534507662958\n",
      "train loss:0.006037567837499848\n",
      "train loss:0.017724828601211818\n",
      "train loss:0.05106732055373243\n",
      "train loss:0.012631696016999133\n",
      "train loss:0.026159545087619748\n",
      "train loss:0.022648529822898732\n",
      "train loss:0.03875438339611572\n",
      "train loss:0.02664655580032429\n",
      "train loss:0.021577154521747563\n",
      "train loss:0.01364564320022313\n",
      "train loss:0.014490812356207415\n",
      "train loss:0.04528420643059147\n",
      "train loss:0.021048317713524067\n",
      "train loss:0.0070559110967585836\n",
      "train loss:0.013711741596045234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.015209322860558507\n",
      "train loss:0.014086570476570477\n",
      "train loss:0.006319589319624249\n",
      "train loss:0.00610523715375563\n",
      "train loss:0.020766698664336822\n",
      "train loss:0.014622410846082122\n",
      "train loss:0.02212550732315975\n",
      "train loss:0.07576920599273339\n",
      "train loss:0.009507200657104812\n",
      "train loss:0.011193702019308955\n",
      "train loss:0.023293533607312577\n",
      "train loss:0.00420843930430043\n",
      "train loss:0.02193022504109449\n",
      "train loss:0.0048119977602744494\n",
      "train loss:0.007827409518925393\n",
      "train loss:0.013033099864835786\n",
      "train loss:0.013042535078295907\n",
      "train loss:0.007015026334917195\n",
      "train loss:0.02064221283290391\n",
      "train loss:0.06305853193121201\n",
      "train loss:0.0052751175853084495\n",
      "train loss:0.0058877798103567055\n",
      "train loss:0.032021338777327706\n",
      "train loss:0.0038830910905705983\n",
      "train loss:0.005121154462368496\n",
      "train loss:0.04654673764115259\n",
      "train loss:0.01359960346028124\n",
      "train loss:0.006111637154440731\n",
      "train loss:0.010620168003593864\n",
      "train loss:0.06164880120368939\n",
      "train loss:0.03716840580695912\n",
      "train loss:0.036233992375633246\n",
      "train loss:0.006255504842406785\n",
      "train loss:0.007758772947515288\n",
      "train loss:0.03225831631826737\n",
      "train loss:0.0027631783515137064\n",
      "train loss:0.0028206056418351643\n",
      "train loss:0.006289565562341583\n",
      "train loss:0.008046600917489845\n",
      "train loss:0.007501895258084847\n",
      "train loss:0.008444271459691908\n",
      "train loss:0.013983896669222513\n",
      "train loss:0.018520016925085918\n",
      "train loss:0.014617743639826682\n",
      "train loss:0.024335589094829056\n",
      "train loss:0.006499971284493264\n",
      "train loss:0.0116799411823117\n",
      "train loss:0.03384024904716357\n",
      "train loss:0.018931246963241097\n",
      "train loss:0.011359840555992602\n",
      "train loss:0.04602451558267782\n",
      "train loss:0.005947276660344054\n",
      "train loss:0.022823465182486843\n",
      "train loss:0.00370952322048525\n",
      "train loss:0.025088727393704827\n",
      "train loss:0.030124029040985566\n",
      "train loss:0.017877633062523355\n",
      "train loss:0.0030157574644378\n",
      "train loss:0.0055633742969333835\n",
      "train loss:0.008987689163743463\n",
      "train loss:0.001691217135914328\n",
      "train loss:0.030972407556099642\n",
      "train loss:0.002531053092876648\n",
      "train loss:0.012431565273836757\n",
      "train loss:0.032708892664185855\n",
      "train loss:0.019023091249086452\n",
      "train loss:0.009309455839995684\n",
      "train loss:0.05321849104296421\n",
      "train loss:0.003883735580032154\n",
      "train loss:0.0287978380317608\n",
      "train loss:0.009640545345189126\n",
      "train loss:0.015941308156200568\n",
      "train loss:0.019640043484433847\n",
      "train loss:0.0059751188179027834\n",
      "train loss:0.021263500014878204\n",
      "train loss:0.018204455672128802\n",
      "train loss:0.004553664695014934\n",
      "train loss:0.009929708029877225\n",
      "train loss:0.03902448913714666\n",
      "train loss:0.008803055217112136\n",
      "train loss:0.007486814884436698\n",
      "train loss:0.008272313391037341\n",
      "train loss:0.10872534020017591\n",
      "train loss:0.008036797044818652\n",
      "train loss:0.015086516100958427\n",
      "train loss:0.021435507830958916\n",
      "train loss:0.0032916521283981996\n",
      "train loss:0.00916034936371087\n",
      "train loss:0.03252967075792878\n",
      "train loss:0.01706732382847347\n",
      "train loss:0.020013463922417197\n",
      "train loss:0.00583672374991189\n",
      "train loss:0.0029504137189886493\n",
      "train loss:0.005444381469964379\n",
      "train loss:0.04176219770741655\n",
      "train loss:0.0066014855850176435\n",
      "train loss:0.020203302783938983\n",
      "train loss:0.014516757649592215\n",
      "train loss:0.0109037046109775\n",
      "train loss:0.01628264407671511\n",
      "train loss:0.017305701595237134\n",
      "train loss:0.002909861705667388\n",
      "train loss:0.007329592764674484\n",
      "train loss:0.001516841655128862\n",
      "train loss:0.0054095816750928715\n",
      "train loss:0.09648278951794322\n",
      "train loss:0.004800330343900112\n",
      "train loss:0.012177718080703108\n",
      "train loss:0.0033027445513727854\n",
      "train loss:0.037472992077897664\n",
      "train loss:0.008074641861299114\n",
      "train loss:0.009959342360762579\n",
      "train loss:0.003597447169626108\n",
      "train loss:0.00898914387991722\n",
      "train loss:0.0402112455162171\n",
      "train loss:0.004417408072986429\n",
      "train loss:0.011364069761673421\n",
      "train loss:0.01555335823188655\n",
      "train loss:0.015601626363755443\n",
      "train loss:0.01347519305410306\n",
      "train loss:0.0017941301738974716\n",
      "train loss:0.006706138502260099\n",
      "train loss:0.006948617138336579\n",
      "train loss:0.0017581242780110023\n",
      "train loss:0.015759519942577536\n",
      "train loss:0.0165469734513162\n",
      "train loss:0.03195734088245259\n",
      "train loss:0.017956619231318582\n",
      "train loss:0.0025157414461253434\n",
      "train loss:0.006042269141683618\n",
      "train loss:0.016420706565208477\n",
      "train loss:0.00662727305418076\n",
      "train loss:0.018885893918627758\n",
      "train loss:0.018215734321630993\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_46969/1004387874.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtrain_convnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/repo/deep-learning-from-scratch/CHAPTER07/train_convnet.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m                   \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_param\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                   evaluate_sample_num_per_epoch=1000)\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# 매개변수 보존\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repo/deep-learning-from-scratch/common/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repo/deep-learning-from-scratch/common/trainer.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train loss:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repo/deep-learning-from-scratch/CHAPTER07/simple_convnet.py\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0m정답\u001b[0m \u001b[0m레이블\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \"\"\"\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repo/deep-learning-from-scratch/CHAPTER07/simple_convnet.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repo/deep-learning-from-scratch/common/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mout_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool_w\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim2col\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool_h\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repo/deep-learning-from-scratch/common/util.py\u001b[0m in \u001b[0;36mim2col\u001b[0;34m(input_data, filter_h, filter_w, stride, pad)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mx_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mout_w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mcol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_max\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx_max\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# print(col.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from train_convnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7fac3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
